{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, LassoCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector, RFE, SelectKBest, mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import boxcox, chi2_contingency\n",
    "from scipy.stats.mstats import winsorize\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette('cividis')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\"..\", \"data\", \"input\", \"train_final.csv\")\n",
    "val_path = os.path.join(\"..\", \"data\", \"input\", \"val_final.csv\")\n",
    "test_path = os.path.join(\"..\", \"data\", \"input\", \"test_final.csv\")\n",
    "y_path = os.path.join(\"..\", \"data\", \"input\", \"y_bin.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_path, index_col=0)\n",
    "X_val = pd.read_csv(val_path, index_col=0)\n",
    "test = pd.read_csv(test_path, index_col=0)\n",
    "y = pd.read_csv(y_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] + X_val.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_mean</th>\n",
       "      <th>non_lab_procedures.1</th>\n",
       "      <th>inpatient_visits_in_previous_year.1</th>\n",
       "      <th>average_pulse_bpm</th>\n",
       "      <th>emergency_visits_in_previous_year.1</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>number_of_medications_log</th>\n",
       "      <th>length_of_stay_in_hospital_log</th>\n",
       "      <th>number_lab_tests.1</th>\n",
       "      <th>race_0</th>\n",
       "      <th>...</th>\n",
       "      <th>is_emergency_visited</th>\n",
       "      <th>is_inpatient_visited</th>\n",
       "      <th>discharge_disposition_cat_0</th>\n",
       "      <th>admission_source_cat_0</th>\n",
       "      <th>admission_source_cat_1</th>\n",
       "      <th>admission_source_cat_3</th>\n",
       "      <th>med_glimepiride</th>\n",
       "      <th>med_insulin</th>\n",
       "      <th>med_repaglinide</th>\n",
       "      <th>med_metformin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672135</th>\n",
       "      <td>1.823370</td>\n",
       "      <td>1.558432</td>\n",
       "      <td>-0.543380</td>\n",
       "      <td>-0.287912</td>\n",
       "      <td>-0.316412</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>1.728691</td>\n",
       "      <td>-0.249231</td>\n",
       "      <td>1.022697</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>-6.324555e-01</td>\n",
       "      <td>-0.597614</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181753</th>\n",
       "      <td>0.547373</td>\n",
       "      <td>-0.198828</td>\n",
       "      <td>-0.543380</td>\n",
       "      <td>1.143652</td>\n",
       "      <td>-0.316412</td>\n",
       "      <td>-0.735636</td>\n",
       "      <td>0.162575</td>\n",
       "      <td>0.156037</td>\n",
       "      <td>-0.154945</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>-5.663831e-17</td>\n",
       "      <td>-0.597614</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890706</th>\n",
       "      <td>1.185371</td>\n",
       "      <td>-0.198828</td>\n",
       "      <td>-0.543380</td>\n",
       "      <td>0.623083</td>\n",
       "      <td>-0.316412</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>-0.238750</td>\n",
       "      <td>0.481067</td>\n",
       "      <td>-1.281386</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>-0.358569</td>\n",
       "      <td>-0.109109</td>\n",
       "      <td>-0.566947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648403</th>\n",
       "      <td>-1.366623</td>\n",
       "      <td>0.972679</td>\n",
       "      <td>0.328783</td>\n",
       "      <td>-1.372431</td>\n",
       "      <td>-0.316412</td>\n",
       "      <td>0.813604</td>\n",
       "      <td>0.285226</td>\n",
       "      <td>-0.795123</td>\n",
       "      <td>-1.742202</td>\n",
       "      <td>-0.632456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.166293</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947413</th>\n",
       "      <td>-1.366623</td>\n",
       "      <td>-0.784582</td>\n",
       "      <td>-0.543380</td>\n",
       "      <td>0.970129</td>\n",
       "      <td>-0.316412</td>\n",
       "      <td>-1.252049</td>\n",
       "      <td>-1.279244</td>\n",
       "      <td>0.156037</td>\n",
       "      <td>-0.001340</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104627</td>\n",
       "      <td>0.083694</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>-0.597614</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.188982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age_mean  non_lab_procedures.1  \\\n",
       "encounter_id                                   \n",
       "672135        1.823370              1.558432   \n",
       "181753        0.547373             -0.198828   \n",
       "890706        1.185371             -0.198828   \n",
       "648403       -1.366623              0.972679   \n",
       "947413       -1.366623             -0.784582   \n",
       "\n",
       "              inpatient_visits_in_previous_year.1  average_pulse_bpm  \\\n",
       "encounter_id                                                           \n",
       "672135                                  -0.543380          -0.287912   \n",
       "181753                                  -0.543380           1.143652   \n",
       "890706                                  -0.543380           0.623083   \n",
       "648403                                   0.328783          -1.372431   \n",
       "947413                                  -0.543380           0.970129   \n",
       "\n",
       "              emergency_visits_in_previous_year.1  number_diagnoses  \\\n",
       "encounter_id                                                          \n",
       "672135                                  -0.316412          0.813604   \n",
       "181753                                  -0.316412         -0.735636   \n",
       "890706                                  -0.316412          0.813604   \n",
       "648403                                  -0.316412          0.813604   \n",
       "947413                                  -0.316412         -1.252049   \n",
       "\n",
       "              number_of_medications_log  length_of_stay_in_hospital_log  \\\n",
       "encounter_id                                                              \n",
       "672135                         1.728691                       -0.249231   \n",
       "181753                         0.162575                        0.156037   \n",
       "890706                        -0.238750                        0.481067   \n",
       "648403                         0.285226                       -0.795123   \n",
       "947413                        -1.279244                        0.156037   \n",
       "\n",
       "              number_lab_tests.1    race_0  ...  is_emergency_visited  \\\n",
       "encounter_id                                ...                         \n",
       "672135                  1.022697 -0.632456  ...              0.104627   \n",
       "181753                 -0.154945 -0.632456  ...              0.104627   \n",
       "890706                 -1.281386 -0.632456  ...              0.104627   \n",
       "648403                 -1.742202 -0.632456  ...              0.104627   \n",
       "947413                 -0.001340 -0.316228  ...              0.104627   \n",
       "\n",
       "              is_inpatient_visited  discharge_disposition_cat_0  \\\n",
       "encounter_id                                                      \n",
       "672135                    0.083694                -6.324555e-01   \n",
       "181753                    0.083694                -5.663831e-17   \n",
       "890706                    0.083694                -3.162278e-01   \n",
       "648403                    0.166293                -3.162278e-01   \n",
       "947413                    0.083694                -3.162278e-01   \n",
       "\n",
       "              admission_source_cat_0  admission_source_cat_1  \\\n",
       "encounter_id                                                   \n",
       "672135                     -0.597614                0.545545   \n",
       "181753                     -0.597614                0.545545   \n",
       "890706                     -0.358569               -0.109109   \n",
       "648403                      0.119523               -0.436436   \n",
       "947413                     -0.597614                0.545545   \n",
       "\n",
       "              admission_source_cat_3  med_glimepiride  med_insulin  \\\n",
       "encounter_id                                                         \n",
       "672135                      0.188982                0            1   \n",
       "181753                      0.188982                0            0   \n",
       "890706                     -0.566947                0            1   \n",
       "648403                      0.377964                0            0   \n",
       "947413                      0.188982                0            1   \n",
       "\n",
       "              med_repaglinide  med_metformin  \n",
       "encounter_id                                  \n",
       "672135                      0              0  \n",
       "181753                      0              0  \n",
       "890706                      0              0  \n",
       "648403                      0              0  \n",
       "947413                      0              0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y.loc[X_train.index]\n",
    "y_val = y.loc[X_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45399, 33)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_val], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 1.0, f1: 1.0\n",
      "Test: Accuracy: 0.839135317237507, f1: 0.2219959266802444\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_rfc = rfc.predict(X_train)\n",
    "y_pred_rfc = rfc.predict(X_val)\n",
    "\n",
    "print(f\"Train: Accuracy: {accuracy_score(y_train, y_train_pred_rfc)}, f1: {f1_score(y_train, y_train_pred_rfc)}\")\n",
    "print(f\"Test: Accuracy: {accuracy_score(y_val, y_pred_rfc)}, f1: {f1_score(y_val, y_pred_rfc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_s = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        value_train = accuracy_score(y_train, y_train_pred)\n",
    "        value_test = accuracy_score(y_val, y_val_pred)\n",
    "        value_f1 = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_s.append(value_f1)\n",
    "        \n",
    "    avg_train = round(np.mean(score_train), 3)\n",
    "    avg_test = round(np.mean(score_test), 3)\n",
    "    std_train = round(np.std(score_train), 2)\n",
    "    std_test = round(np.std(score_test), 2)\n",
    "    avg_f1 = round(np.mean(f1_s), 6)\n",
    "    std_f1 = round(np.std(f1_s), 6)\n",
    "\n",
    "    return str(avg_train) + '+/-' + str(std_train), \\\n",
    "        str(avg_test) + '+/-' + str(std_test), str(avg_f1) + '+/-' + str(std_f1)\n",
    "\n",
    "def show_results(df, *args):\n",
    "    for i, arg in enumerate(args):\n",
    "        print(f\"{i+1}th call of rfc: {arg}\")\n",
    "        avg_train, avg_test, f1 = evaluate(arg)\n",
    "        df.iloc[i] = avg_train, avg_test, f1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling rfe with n_est 50\n",
      "calling rfe with n_est 100\n",
      "calling rfe with n_est 200\n",
      "calling rfe with n_est 300\n",
      "calling rfe with n_est 500\n"
     ]
    }
   ],
   "source": [
    "## reviewing the number of estimators used\n",
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=value,\n",
    "            max_depth=8\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "n_est = [50, 100, 200, 300, 500]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=n_est)\n",
    "\n",
    "results_est = show_results(results_empty, *n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.999+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.206221+/-0.012949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.207935+/-0.006996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.203993+/-0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.20494+/-0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.199407+/-0.011285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "50   0.999+/-0.0  0.835+/-0.0  0.206221+/-0.012949\n",
       "100    1.0+/-0.0  0.835+/-0.0  0.207935+/-0.006996\n",
       "200    1.0+/-0.0  0.836+/-0.0    0.203993+/-0.0094\n",
       "300    1.0+/-0.0  0.836+/-0.0   0.20494+/-0.008733\n",
       "500    1.0+/-0.0  0.836+/-0.0  0.199407+/-0.011285"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_depth=2, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_depth=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_depth=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_depth=12, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_depth=16, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=100,\n",
    "            max_depth=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "depths = [2, 4, 8, 12, 16, None]\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=depths)\n",
    "\n",
    "results_depth = show_results(results_empty, *get_models(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.0+/-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.826+/-0.0</td>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.008006+/-0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.838+/-0.0</td>\n",
       "      <td>0.831+/-0.0</td>\n",
       "      <td>0.102809+/-0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.863+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.157024+/-0.010716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.911+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.191782+/-0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.209879+/-0.007245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train         Test                   f1\n",
       "2.0   0.825+/-0.0  0.825+/-0.0            0.0+/-0.0\n",
       "4.0   0.826+/-0.0  0.825+/-0.0  0.008006+/-0.002687\n",
       "8.0   0.838+/-0.0  0.831+/-0.0  0.102809+/-0.015984\n",
       "12.0  0.863+/-0.0  0.834+/-0.0  0.157024+/-0.010716\n",
       "16.0  0.911+/-0.0  0.835+/-0.0  0.191782+/-0.005791\n",
       "NaN     1.0+/-0.0  0.836+/-0.0  0.209879+/-0.007245"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(min_samples_split=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(min_samples_split=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(min_samples_split=16, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(min_samples_split=32, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(min_samples_split=64, random_state=69)\n",
      "7th call of rfc: RandomForestClassifier(min_samples_split=128, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.205121+/-0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.209059+/-0.011962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.923+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.206717+/-0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.88+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.195921+/-0.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.856+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.176999+/-0.013797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.843+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.162672+/-0.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.833+/-0.0</td>\n",
       "      <td>0.138544+/-0.010453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "2      1.0+/-0.0  0.836+/-0.0  0.205121+/-0.003511\n",
       "4    0.984+/-0.0  0.835+/-0.0  0.209059+/-0.011962\n",
       "8    0.923+/-0.0  0.836+/-0.0  0.206717+/-0.007306\n",
       "16    0.88+/-0.0  0.836+/-0.0  0.195921+/-0.013186\n",
       "32   0.856+/-0.0  0.835+/-0.0  0.176999+/-0.013797\n",
       "64   0.843+/-0.0  0.835+/-0.0  0.162672+/-0.009995\n",
       "128  0.837+/-0.0  0.833+/-0.0  0.138544+/-0.010453"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            min_samples_split=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "splits = [2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=splits)\n",
    "\n",
    "results_min_split = show_results(results_empty, *get_models(splits))\n",
    "results_min_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_samples=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_samples=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_samples=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_samples=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_samples=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.846+/-0.0</td>\n",
       "      <td>0.832+/-0.0</td>\n",
       "      <td>0.148549+/-0.008243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.864+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.169845+/-0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.914+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.18544+/-0.005221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.974+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.200419+/-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.998+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.20819+/-0.011787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.212397+/-0.00629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "0.1  0.846+/-0.0  0.832+/-0.0  0.148549+/-0.008243\n",
       "0.2  0.864+/-0.0  0.834+/-0.0  0.169845+/-0.008981\n",
       "0.4  0.914+/-0.0  0.835+/-0.0   0.18544+/-0.005221\n",
       "0.6  0.974+/-0.0  0.835+/-0.0  0.200419+/-0.016275\n",
       "0.8  0.998+/-0.0  0.836+/-0.0   0.20819+/-0.011787\n",
       "NaN    1.0+/-0.0  0.836+/-0.0   0.212397+/-0.00629"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_samples=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_samples = show_results(results_empty, *get_models(samples))\n",
    "results_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_features=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_features=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_features=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_features=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_features=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(max_features=None, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.172304+/-0.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.221058+/-0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.257206+/-0.008665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.264981+/-0.009177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.281189+/-0.009322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.285535+/-0.010913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train         Test                   f1\n",
       "0.1  1.0+/-0.0  0.834+/-0.0  0.172304+/-0.018237\n",
       "0.2  1.0+/-0.0  0.836+/-0.0  0.221058+/-0.007162\n",
       "0.4  1.0+/-0.0  0.837+/-0.0  0.257206+/-0.008665\n",
       "0.6  1.0+/-0.0  0.835+/-0.0  0.264981+/-0.009177\n",
       "0.8  1.0+/-0.0  0.836+/-0.0  0.281189+/-0.009322\n",
       "NaN  1.0+/-0.0  0.836+/-0.0  0.285535+/-0.010913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_features=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_feat = show_results(results_empty, *get_models(samples))\n",
    "results_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'max_samples': None, 'min_samples_split': 4}\n",
      "Accuracy on Test Set: 0.8312745648512072\n",
      "f1 on Test Set: 0.2397216951296648\n"
     ]
    }
   ],
   "source": [
    "# performing a grid search with the best values\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [12, 16, None],\n",
    "    'min_samples_split': [4, 8, 16],\n",
    "    'max_samples': [0.6, 0.8, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = best_rf_classifier.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")\n",
    "print(f\"f1 on Test Set: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_rfc = RandomForestClassifier(min_samples_split = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning\n",
    "\n",
    "will start directly with a random search, and then zoom in manually into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END activation=sigmoid, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   2.2s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   2.5s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.8s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   2.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.3s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.7s\n",
      "[CV] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.8s\n",
      "[CV] END activation=sigmoid, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   0.6s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.9s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   3.8s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=   3.7s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.1, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   1.8s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.1, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   1.6s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.1, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   1.7s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.1, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   1.5s\n",
      "[CV] END activation=tanh, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.1, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   1.3s\n",
      "[CV] END activation=tanh, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=  17.7s\n",
      "[CV] END activation=tanh, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=  17.8s\n",
      "[CV] END activation=tanh, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=  18.3s\n",
      "[CV] END activation=tanh, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=  17.7s\n",
      "[CV] END activation=tanh, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1; total time=  17.8s\n",
      "[CV] END activation=sigmoid, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.01, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.01, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.01, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.01, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "[CV] END activation=sigmoid, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.01, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1; total time=   0.0s\n",
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.0001, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.01, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.4056838193271968\n",
      "Standard Deviation of Test Score: 0.01752403899441504\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.37932709695910216\n",
      "Standard Deviation of Test Score: 0.013011996251727437\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.01, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.2866632588705288\n",
      "Standard Deviation of Test Score: 0.024968295799138913\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (100, 50), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.28562652144760803\n",
      "Standard Deviation of Test Score: 0.015699618634121195\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.2826657032178834\n",
      "Standard Deviation of Test Score: 0.01173746439746875\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier(random_state=69)\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100, 50,), (100, 100, 50,)],\n",
    "    'max_iter': [10, 100, 200, 500],\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1],\n",
    "    'n_iter_no_change': [5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=mlp_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1', random_state=69, verbose=1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.61919403e-03, 1.82109284e+00, 1.10654855e+00, 3.03378105e-03,\n",
       "        6.78336620e-01, 1.89102073e+00, 3.79119730e+00, 1.65822263e+00,\n",
       "        1.79598830e+01, 3.01470757e-03]),\n",
       " 'std_fit_time': array([5.11930317e-04, 7.59441818e-01, 4.51067515e-01, 8.83858030e-05,\n",
       "        1.29925489e-02, 7.05474773e-02, 3.95697924e-02, 1.69730612e-01,\n",
       "        2.14975348e-01, 6.61634807e-04]),\n",
       " 'mean_score_time': array([0.        , 0.0076519 , 0.00797229, 0.        , 0.00977125,\n",
       "        0.00924149, 0.00781903, 0.01296096, 0.01214128, 0.        ]),\n",
       " 'std_score_time': array([0.        , 0.00049389, 0.00104848, 0.        , 0.00078557,\n",
       "        0.00066491, 0.00042658, 0.00129318, 0.00108396, 0.        ]),\n",
       " 'param_validation_fraction': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['adam', 'adam', 'sgd', 'sgd', 'lbfgs', 'sgd', 'lbfgs',\n",
       "                    'adam', 'lbfgs', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_iter_no_change': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[100, 200, 200, 100, 10, 10, 200, 200, 200, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate_init': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.1, 0.1, 0.01, 0.1, 0.001,\n",
       "                    0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[(100, 100, 50), (50,), (50,), (100, 100, 50),\n",
       "                    (100, 50), (100, 50), (50,), (100, 100, 50),\n",
       "                    (100, 100, 50), (100, 100, 50)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[32, 32, 64, 64, 128, 32, 128, 64, 32, 64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.01,\n",
       "                    0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_activation': masked_array(data=['sigmoid', 'tanh', 'relu', 'sigmoid', 'relu', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'sigmoid'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'relu'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'sigmoid'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 128,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'relu'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.01,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 128,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.01,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'sigmoid'}],\n",
       " 'split0_test_score': array([       nan, 0.31698565, 0.29187192,        nan, 0.3007335 ,\n",
       "        0.27812114, 0.37974684, 0.31156381, 0.39982031,        nan]),\n",
       " 'split1_test_score': array([       nan, 0.26379201, 0.27424336,        nan, 0.27244582,\n",
       "        0.26335878, 0.38645418, 0.17793103, 0.39839929,        nan]),\n",
       " 'split2_test_score': array([       nan, 0.27977316, 0.28325123,        nan, 0.3039807 ,\n",
       "        0.25016119, 0.3972468 , 0.32105869, 0.42985843,        nan]),\n",
       " 'split3_test_score': array([       nan, 0.25786164, 0.26567349,        nan, 0.26348808,\n",
       "        0.26108682, 0.35792779, 0.27870813, 0.38013544,        nan]),\n",
       " 'split4_test_score': array([       nan, 0.31490385, 0.29828851,        nan, 0.28748451,\n",
       "        0.24661072, 0.37525988, 0.22413793, 0.42020563,        nan]),\n",
       " 'mean_test_score': array([       nan, 0.28666326, 0.2826657 ,        nan, 0.28562652,\n",
       "        0.25986773, 0.3793271 , 0.26267992, 0.40568382,        nan]),\n",
       " 'std_test_score': array([       nan, 0.0249683 , 0.01173746,        nan, 0.01569962,\n",
       "        0.01110699, 0.013012  , 0.05426321, 0.01752404,        nan]),\n",
       " 'rank_test_score': array([8, 3, 5, 8, 4, 7, 2, 6, 1, 8])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.8763442586112805\n",
      "Test: Accuracy: 0.7585626052779337, f1: 0.23111309789897186\n"
     ]
    }
   ],
   "source": [
    "chosen_mlp = MLPClassifier(validation_fraction = 0.1, solver = 'lbfgs', n_iter_no_change = 5, max_iter = 200, learning_rate_init = 0.001, hidden_layer_sizes = (100, 50, 20), early_stopping = True, batch_size = 32, alpha = 0.001, activation = 'relu')\n",
    "chosen_mlp.fit(X_train, y_train)\n",
    "y_train_pred = chosen_mlp.predict(X_train)\n",
    "y_val_pred = chosen_mlp.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.9878655580880229\n",
      "Test: Accuracy: 0.840398652442448, f1: 0.2348586810228802\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier()\n",
    "ch_rfc.fit(X_train, y_train)\n",
    "y_train_pred = ch_rfc.predict(X_train)\n",
    "y_val_pred = ch_rfc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbc.fit(X, y)\n",
    "test_pred = chosen_mlp.predict(test)\n",
    "\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted_binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499502</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447319</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181183</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359339</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              readmitted_binary\n",
       "encounter_id                   \n",
       "499502                        0\n",
       "447319                        1\n",
       "309126                        0\n",
       "181183                        0\n",
       "359339                        0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame(test_pred, columns=['readmitted_binary'], index=test.index)\n",
    "\n",
    "to_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30530\n",
       "unique        2\n",
       "top          No\n",
       "freq      24338\n",
       "Name: readmitted_binary, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = to_submit['readmitted_binary'].map({1: 'Yes', 0: 'No'})\n",
    "to_submit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.to_csv(\"../data/output/submission_nn_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_mean', 'non_lab_procedures.1',\n",
       "       'inpatient_visits_in_previous_year.1', 'average_pulse_bpm',\n",
       "       'emergency_visits_in_previous_year.1', 'number_diagnoses',\n",
       "       'number_of_medications_log', 'length_of_stay_in_hospital_log',\n",
       "       'number_lab_tests.1', 'race_0', 'race_3', 'gender', 'age_0', 'age_2',\n",
       "       'age_4', 'age_5', 'age_6', 'age_8', 'admission_type_4',\n",
       "       'discharge_disposition', 'a1c_test_result_2',\n",
       "       'change_in_meds_during_hospitalization', 'is_outpatient_visited',\n",
       "       'is_emergency_visited', 'is_inpatient_visited',\n",
       "       'discharge_disposition_cat_0', 'admission_source_cat_0',\n",
       "       'admission_source_cat_1', 'admission_source_cat_3', 'med_glimepiride',\n",
       "       'med_insulin', 'med_repaglinide', 'med_metformin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-23-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
