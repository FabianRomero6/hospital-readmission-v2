{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, LassoCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector, RFE, SelectKBest, mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import boxcox, chi2_contingency\n",
    "from scipy.stats.mstats import winsorize\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette('cividis')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\"..\", \"data\", \"input\", \"train_final.csv\")\n",
    "val_path = os.path.join(\"..\", \"data\", \"input\", \"val_final.csv\")\n",
    "test_path = os.path.join(\"..\", \"data\", \"input\", \"test_final.csv\")\n",
    "y_train_path = os.path.join(\"..\", \"data\", \"input\", \"y_train.csv\")\n",
    "y_path = os.path.join(\"..\", \"data\", \"input\", \"target.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_path, index_col=0)\n",
    "X_val = pd.read_csv(val_path, index_col=0)\n",
    "test = pd.read_csv(test_path, index_col=0)\n",
    "y_train = pd.read_csv(y_train_path, index_col=0)\n",
    "y = pd.read_csv(y_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length_of_stay_in_hospital_win_log</th>\n",
       "      <th>number_of_medications_log</th>\n",
       "      <th>number_of_medications</th>\n",
       "      <th>inpatient_visits_in_previous_year</th>\n",
       "      <th>number_lab_tests</th>\n",
       "      <th>inpatient_visits_in_previous_year_win_log</th>\n",
       "      <th>inpatient_visits_in_previous_year_log</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>length_of_stay_in_hospital_log</th>\n",
       "      <th>secondary_diagnosis_cat</th>\n",
       "      <th>...</th>\n",
       "      <th>glucose_test_result_1</th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_8</th>\n",
       "      <th>primary_diagnosis_cat</th>\n",
       "      <th>discharge_disposition_cat_0</th>\n",
       "      <th>is_outpatient_visited</th>\n",
       "      <th>admission_type_4</th>\n",
       "      <th>is_inpatient_visited</th>\n",
       "      <th>is_emergency_visited</th>\n",
       "      <th>med_insulin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.250351</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>-0.162162</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.250351</td>\n",
       "      <td>0.498963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.495434</td>\n",
       "      <td>-0.004535</td>\n",
       "      <td>0.469926</td>\n",
       "      <td>-6.324555e-01</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>-0.062994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281196</td>\n",
       "      <td>-0.440172</td>\n",
       "      <td>-0.837838</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.025641</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.281196</td>\n",
       "      <td>0.542178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.385337</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.488402</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>-0.062994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.539649</td>\n",
       "      <td>-0.440172</td>\n",
       "      <td>-0.837838</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.521368</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.466667</td>\n",
       "      <td>-0.539649</td>\n",
       "      <td>0.504612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.275241</td>\n",
       "      <td>-0.163266</td>\n",
       "      <td>0.482256</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>-0.062994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.539649</td>\n",
       "      <td>-0.565384</td>\n",
       "      <td>-0.891892</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>-0.418803</td>\n",
       "      <td>0.971985</td>\n",
       "      <td>0.930607</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>-0.539649</td>\n",
       "      <td>0.493242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.385337</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.501362</td>\n",
       "      <td>-3.162278e-01</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>-0.062994</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.035577</td>\n",
       "      <td>-0.063809</td>\n",
       "      <td>-0.594595</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.035577</td>\n",
       "      <td>0.504476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.385337</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.552466</td>\n",
       "      <td>-5.663831e-17</td>\n",
       "      <td>0.486817</td>\n",
       "      <td>-0.062994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length_of_stay_in_hospital_win_log  number_of_medications_log  \\\n",
       "0                           -0.250351                   0.345000   \n",
       "1                            0.281196                  -0.440172   \n",
       "2                           -0.539649                  -0.440172   \n",
       "3                           -0.539649                  -0.565384   \n",
       "4                           -0.035577                  -0.063809   \n",
       "\n",
       "   number_of_medications  inpatient_visits_in_previous_year  number_lab_tests  \\\n",
       "0              -0.162162                          -1.000000          0.059829   \n",
       "1              -0.837838                          -1.000000         -0.025641   \n",
       "2              -0.837838                          -1.000000         -0.521368   \n",
       "3              -0.891892                          -0.714286         -0.418803   \n",
       "4              -0.594595                          -1.000000         -0.333333   \n",
       "\n",
       "   inpatient_visits_in_previous_year_win_log  \\\n",
       "0                                  -1.000000   \n",
       "1                                  -1.000000   \n",
       "2                                  -1.000000   \n",
       "3                                   0.971985   \n",
       "4                                  -1.000000   \n",
       "\n",
       "   inpatient_visits_in_previous_year_log  number_diagnoses  \\\n",
       "0                              -1.000000          0.066667   \n",
       "1                              -1.000000         -0.333333   \n",
       "2                              -1.000000         -0.466667   \n",
       "3                               0.930607          0.066667   \n",
       "4                              -1.000000         -0.333333   \n",
       "\n",
       "   length_of_stay_in_hospital_log  secondary_diagnosis_cat  ...  \\\n",
       "0                       -0.250351                 0.498963  ...   \n",
       "1                        0.281196                 0.542178  ...   \n",
       "2                       -0.539649                 0.504612  ...   \n",
       "3                       -0.539649                 0.493242  ...   \n",
       "4                       -0.035577                 0.504476  ...   \n",
       "\n",
       "   glucose_test_result_1     age_0     age_8  primary_diagnosis_cat  \\\n",
       "0                    0.5 -0.495434 -0.004535               0.469926   \n",
       "1                    0.5 -0.385337  0.040816               0.488402   \n",
       "2                    0.5 -0.275241 -0.163266               0.482256   \n",
       "3                    0.5 -0.385337  0.040816               0.501362   \n",
       "4                    0.5 -0.385337  0.040816               0.552466   \n",
       "\n",
       "   discharge_disposition_cat_0  is_outpatient_visited  admission_type_4  \\\n",
       "0                -6.324555e-01               0.486817         -0.062994   \n",
       "1                -3.162278e-01               0.486817         -0.062994   \n",
       "2                -3.162278e-01               0.486817         -0.062994   \n",
       "3                -3.162278e-01               0.486817         -0.062994   \n",
       "4                -5.663831e-17               0.486817         -0.062994   \n",
       "\n",
       "   is_inpatient_visited  is_emergency_visited  med_insulin  \n",
       "0                   0.0              0.481634            1  \n",
       "1                   0.0              0.481634            1  \n",
       "2                   0.0              0.481634            0  \n",
       "3                   1.0              0.481634            0  \n",
       "4                   0.0              0.481634            0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y.loc[X_val.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace({'Yes': 1, 'No': 0})\n",
    "y_val = y_val.replace({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.copy()\n",
    "y = y_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 1.0, f1: 1.0\n",
      "Test: Accuracy: 0.834292532285233, f1: 0.22969004893964112\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_rfc = rfc.predict(X_train)\n",
    "y_pred_rfc = rfc.predict(X_val)\n",
    "\n",
    "print(f\"Train: Accuracy: {accuracy_score(y_train, y_train_pred_rfc)}, f1: {f1_score(y_train, y_train_pred_rfc, pos_label='Yes')}\")\n",
    "print(f\"Test: Accuracy: {accuracy_score(y_val, y_pred_rfc)}, f1: {f1_score(y_val, y_pred_rfc, pos_label='Yes')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_s = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        value_train = accuracy_score(y_train, y_train_pred)\n",
    "        value_test = accuracy_score(y_val, y_val_pred)\n",
    "        value_f1 = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_s.append(value_f1)\n",
    "        \n",
    "    avg_train = round(np.mean(score_train), 3)\n",
    "    avg_test = round(np.mean(score_test), 3)\n",
    "    std_train = round(np.std(score_train), 2)\n",
    "    std_test = round(np.std(score_test), 2)\n",
    "    avg_f1 = round(np.mean(f1_s), 6)\n",
    "    std_f1 = round(np.std(f1_s), 6)\n",
    "\n",
    "    return str(avg_train) + '+/-' + str(std_train), \\\n",
    "        str(avg_test) + '+/-' + str(std_test), str(avg_f1) + '+/-' + str(std_f1)\n",
    "\n",
    "def show_results(df, *args):\n",
    "    for i, arg in enumerate(args):\n",
    "        print(f\"{i+1}th call of rfc: {arg}\")\n",
    "        avg_train, avg_test, f1 = evaluate(arg)\n",
    "        df.iloc[i] = avg_train, avg_test, f1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling rfe with n_est 50\n",
      "calling rfe with n_est 100\n",
      "calling rfe with n_est 200\n",
      "calling rfe with n_est 300\n",
      "calling rfe with n_est 500\n"
     ]
    }
   ],
   "source": [
    "## reviewing the number of estimators used\n",
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=value,\n",
    "            max_depth=8\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "n_est = [50, 100, 200, 300, 500]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=n_est)\n",
    "\n",
    "results_est = show_results(results_empty, *n_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.999+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.206221+/-0.012949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.207935+/-0.006996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.203993+/-0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.20494+/-0.008733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.199407+/-0.011285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "50   0.999+/-0.0  0.835+/-0.0  0.206221+/-0.012949\n",
       "100    1.0+/-0.0  0.835+/-0.0  0.207935+/-0.006996\n",
       "200    1.0+/-0.0  0.836+/-0.0    0.203993+/-0.0094\n",
       "300    1.0+/-0.0  0.836+/-0.0   0.20494+/-0.008733\n",
       "500    1.0+/-0.0  0.836+/-0.0  0.199407+/-0.011285"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_depth=2, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_depth=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_depth=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_depth=12, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_depth=16, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=100,\n",
    "            max_depth=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "depths = [2, 4, 8, 12, 16, None]\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=depths)\n",
    "\n",
    "results_depth = show_results(results_empty, *get_models(depths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.0+/-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.826+/-0.0</td>\n",
       "      <td>0.825+/-0.0</td>\n",
       "      <td>0.008006+/-0.002687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.838+/-0.0</td>\n",
       "      <td>0.831+/-0.0</td>\n",
       "      <td>0.102809+/-0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.863+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.157024+/-0.010716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.911+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.191782+/-0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.209879+/-0.007245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train         Test                   f1\n",
       "2.0   0.825+/-0.0  0.825+/-0.0            0.0+/-0.0\n",
       "4.0   0.826+/-0.0  0.825+/-0.0  0.008006+/-0.002687\n",
       "8.0   0.838+/-0.0  0.831+/-0.0  0.102809+/-0.015984\n",
       "12.0  0.863+/-0.0  0.834+/-0.0  0.157024+/-0.010716\n",
       "16.0  0.911+/-0.0  0.835+/-0.0  0.191782+/-0.005791\n",
       "NaN     1.0+/-0.0  0.836+/-0.0  0.209879+/-0.007245"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(min_samples_split=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(min_samples_split=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(min_samples_split=16, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(min_samples_split=32, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(min_samples_split=64, random_state=69)\n",
      "7th call of rfc: RandomForestClassifier(min_samples_split=128, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.205121+/-0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.209059+/-0.011962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.923+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.206717+/-0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.88+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.195921+/-0.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.856+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.176999+/-0.013797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.843+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.162672+/-0.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.833+/-0.0</td>\n",
       "      <td>0.138544+/-0.010453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "2      1.0+/-0.0  0.836+/-0.0  0.205121+/-0.003511\n",
       "4    0.984+/-0.0  0.835+/-0.0  0.209059+/-0.011962\n",
       "8    0.923+/-0.0  0.836+/-0.0  0.206717+/-0.007306\n",
       "16    0.88+/-0.0  0.836+/-0.0  0.195921+/-0.013186\n",
       "32   0.856+/-0.0  0.835+/-0.0  0.176999+/-0.013797\n",
       "64   0.843+/-0.0  0.835+/-0.0  0.162672+/-0.009995\n",
       "128  0.837+/-0.0  0.833+/-0.0  0.138544+/-0.010453"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            min_samples_split=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "splits = [2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=splits)\n",
    "\n",
    "results_min_split = show_results(results_empty, *get_models(splits))\n",
    "results_min_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_samples=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_samples=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_samples=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_samples=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_samples=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.846+/-0.0</td>\n",
       "      <td>0.832+/-0.0</td>\n",
       "      <td>0.148549+/-0.008243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.864+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.169845+/-0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.914+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.18544+/-0.005221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.974+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.200419+/-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.998+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.20819+/-0.011787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.212397+/-0.00629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "0.1  0.846+/-0.0  0.832+/-0.0  0.148549+/-0.008243\n",
       "0.2  0.864+/-0.0  0.834+/-0.0  0.169845+/-0.008981\n",
       "0.4  0.914+/-0.0  0.835+/-0.0   0.18544+/-0.005221\n",
       "0.6  0.974+/-0.0  0.835+/-0.0  0.200419+/-0.016275\n",
       "0.8  0.998+/-0.0  0.836+/-0.0   0.20819+/-0.011787\n",
       "NaN    1.0+/-0.0  0.836+/-0.0   0.212397+/-0.00629"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_samples=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_samples = show_results(results_empty, *get_models(samples))\n",
    "results_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_features=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_features=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_features=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_features=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_features=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(max_features=None, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.172304+/-0.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.221058+/-0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.257206+/-0.008665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.264981+/-0.009177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.281189+/-0.009322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.285535+/-0.010913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train         Test                   f1\n",
       "0.1  1.0+/-0.0  0.834+/-0.0  0.172304+/-0.018237\n",
       "0.2  1.0+/-0.0  0.836+/-0.0  0.221058+/-0.007162\n",
       "0.4  1.0+/-0.0  0.837+/-0.0  0.257206+/-0.008665\n",
       "0.6  1.0+/-0.0  0.835+/-0.0  0.264981+/-0.009177\n",
       "0.8  1.0+/-0.0  0.836+/-0.0  0.281189+/-0.009322\n",
       "NaN  1.0+/-0.0  0.836+/-0.0  0.285535+/-0.010913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_features=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_feat = show_results(results_empty, *get_models(samples))\n",
    "results_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=8;, score=nan total time=  18.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=8;, score=nan total time=  18.3s\n",
      "[CV 3/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=8;, score=nan total time=  18.5s\n",
      "[CV 4/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=8;, score=nan total time=  18.5s\n",
      "[CV 5/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=8;, score=nan total time=  18.3s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_samples=0.8, min_samples_split=16;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_samples=0.8, min_samples_split=16;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_samples=0.8, min_samples_split=16;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_samples=0.8, min_samples_split=16;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_samples=0.8, min_samples_split=16;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_samples=None, min_samples_split=4;, score=nan total time=  37.1s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_samples=None, min_samples_split=4;, score=nan total time=  40.5s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_samples=None, min_samples_split=4;, score=nan total time=  40.2s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_samples=None, min_samples_split=4;, score=nan total time=  40.3s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_samples=None, min_samples_split=4;, score=nan total time=  39.8s\n",
      "[CV 1/5] END bootstrap=True, max_depth=None, max_samples=0.8, min_samples_split=8;, score=nan total time=  27.0s\n",
      "[CV 2/5] END bootstrap=True, max_depth=None, max_samples=0.8, min_samples_split=8;, score=nan total time=  25.0s\n",
      "[CV 3/5] END bootstrap=True, max_depth=None, max_samples=0.8, min_samples_split=8;, score=nan total time=  24.7s\n",
      "[CV 4/5] END bootstrap=True, max_depth=None, max_samples=0.8, min_samples_split=8;, score=nan total time=  24.9s\n",
      "[CV 5/5] END bootstrap=True, max_depth=None, max_samples=0.8, min_samples_split=8;, score=nan total time=  24.9s\n",
      "[CV 1/5] END bootstrap=True, max_depth=12, max_samples=0.6, min_samples_split=8;, score=nan total time=  11.6s\n",
      "[CV 2/5] END bootstrap=True, max_depth=12, max_samples=0.6, min_samples_split=8;, score=nan total time=  12.1s\n",
      "[CV 3/5] END bootstrap=True, max_depth=12, max_samples=0.6, min_samples_split=8;, score=nan total time=  11.9s\n",
      "[CV 4/5] END bootstrap=True, max_depth=12, max_samples=0.6, min_samples_split=8;, score=nan total time=  11.8s\n",
      "[CV 5/5] END bootstrap=True, max_depth=12, max_samples=0.6, min_samples_split=8;, score=nan total time=  13.0s\n",
      "[CV 1/5] END bootstrap=True, max_depth=12, max_samples=0.8, min_samples_split=4;, score=nan total time=  14.5s\n",
      "[CV 2/5] END bootstrap=True, max_depth=12, max_samples=0.8, min_samples_split=4;, score=nan total time=  14.4s\n",
      "[CV 3/5] END bootstrap=True, max_depth=12, max_samples=0.8, min_samples_split=4;, score=nan total time=  14.3s\n",
      "[CV 4/5] END bootstrap=True, max_depth=12, max_samples=0.8, min_samples_split=4;, score=nan total time=  14.4s\n",
      "[CV 5/5] END bootstrap=True, max_depth=12, max_samples=0.8, min_samples_split=4;, score=nan total time=  14.1s\n",
      "[CV 1/5] END bootstrap=False, max_depth=16, max_samples=None, min_samples_split=8;, score=nan total time=  25.4s\n",
      "[CV 2/5] END bootstrap=False, max_depth=16, max_samples=None, min_samples_split=8;, score=nan total time=  25.6s\n",
      "[CV 3/5] END bootstrap=False, max_depth=16, max_samples=None, min_samples_split=8;, score=nan total time=  25.5s\n",
      "[CV 4/5] END bootstrap=False, max_depth=16, max_samples=None, min_samples_split=8;, score=nan total time=  28.1s\n",
      "[CV 5/5] END bootstrap=False, max_depth=16, max_samples=None, min_samples_split=8;, score=nan total time=  31.1s\n",
      "[CV 1/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=16;, score=nan total time=  21.2s\n",
      "[CV 2/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=16;, score=nan total time=  19.7s\n",
      "[CV 3/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=16;, score=nan total time=  19.6s\n",
      "[CV 4/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=16;, score=nan total time=  20.2s\n",
      "[CV 5/5] END bootstrap=True, max_depth=16, max_samples=0.8, min_samples_split=16;, score=nan total time=  21.2s\n",
      "[CV 1/5] END bootstrap=False, max_depth=None, max_samples=0.6, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=None, max_samples=0.6, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=None, max_samples=0.6, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=None, max_samples=0.6, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=None, max_samples=0.6, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 1/5] END bootstrap=False, max_depth=16, max_samples=0.8, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 2/5] END bootstrap=False, max_depth=16, max_samples=0.8, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 3/5] END bootstrap=False, max_depth=16, max_samples=0.8, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 4/5] END bootstrap=False, max_depth=16, max_samples=0.8, min_samples_split=4;, score=nan total time=   0.0s\n",
      "[CV 5/5] END bootstrap=False, max_depth=16, max_samples=0.8, min_samples_split=4;, score=nan total time=   0.0s\n",
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'min_samples_split': 4, 'max_samples': 0.8, 'max_depth': 16, 'bootstrap': False}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'min_samples_split': 4, 'max_samples': 0.6, 'max_depth': None, 'bootstrap': False}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'min_samples_split': 16, 'max_samples': 0.8, 'max_depth': 16, 'bootstrap': True}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'min_samples_split': 8, 'max_samples': None, 'max_depth': 16, 'bootstrap': False}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'min_samples_split': 4, 'max_samples': 0.8, 'max_depth': 12, 'bootstrap': True}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'min_samples_split': 8, 'max_samples': 0.6, 'max_depth': 12, 'bootstrap': True}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'min_samples_split': 8, 'max_samples': 0.8, 'max_depth': None, 'bootstrap': True}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'min_samples_split': 4, 'max_samples': None, 'max_depth': None, 'bootstrap': False}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n"
     ]
    }
   ],
   "source": [
    "# performing a grid search with the best values\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [12, 16, None],\n",
    "    'min_samples_split': [4, 8, 16],\n",
    "    'max_samples': [0.6, 0.8, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_classifier, param_distributions=param_grid, cv=5, scoring='f1', verbose=3)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_rfc = RandomForestClassifier(min_samples_split = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning\n",
    "\n",
    "will start directly with a random search, and then zoom in manually into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.629 total time=  18.3s\n",
      "[CV 2/5] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.633 total time=  18.2s\n",
      "[CV 3/5] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.628 total time=  18.8s\n",
      "[CV 4/5] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.639 total time=  20.1s\n",
      "[CV 5/5] END activation=tanh, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.630 total time=  19.4s\n",
      "[CV 1/5] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.628 total time=   3.0s\n",
      "[CV 2/5] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.634 total time=   3.2s\n",
      "[CV 3/5] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.631 total time=   3.2s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.640 total time=   2.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.634 total time=   3.0s\n",
      "[CV 1/5] END activation=logistic, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.629 total time=  21.9s\n",
      "[CV 2/5] END activation=logistic, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.632 total time=  21.6s\n",
      "[CV 3/5] END activation=logistic, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.632 total time=  21.7s\n",
      "[CV 4/5] END activation=logistic, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.633 total time=  22.2s\n",
      "[CV 5/5] END activation=logistic, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.629 total time=  18.7s\n",
      "[CV 1/5] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.656 total time=  32.6s\n",
      "[CV 2/5] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.665 total time=  32.0s\n",
      "[CV 3/5] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.656 total time=  34.3s\n",
      "[CV 4/5] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.665 total time=  35.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.661 total time=  37.2s\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.619 total time=  17.7s\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.628 total time=  18.7s\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.626 total time=  10.7s\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.643 total time=  15.0s\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(100, 50), learning_rate_init=0.001, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.604 total time=  15.8s\n",
      "[CV 1/5] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.612 total time=   3.8s\n",
      "[CV 2/5] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.652 total time=   3.7s\n",
      "[CV 3/5] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.605 total time=   3.6s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.660 total time=   3.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, batch_size=32, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.1, max_iter=10, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.636 total time=   3.6s\n",
      "[CV 1/5] END activation=relu, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.686 total time= 1.1min\n",
      "[CV 2/5] END activation=relu, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.664 total time= 1.1min\n",
      "[CV 3/5] END activation=relu, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.672 total time= 1.1min\n",
      "[CV 4/5] END activation=relu, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.669 total time= 1.2min\n",
      "[CV 5/5] END activation=relu, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(100, 100, 50), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.680 total time= 1.1min\n",
      "[CV 1/5] END activation=relu, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.647 total time=   5.1s\n",
      "[CV 2/5] END activation=relu, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.658 total time=  10.6s\n",
      "[CV 3/5] END activation=relu, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.631 total time=  14.3s\n",
      "[CV 4/5] END activation=relu, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.644 total time=   6.6s\n",
      "[CV 5/5] END activation=relu, alpha=0.01, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.632 total time=   7.4s\n",
      "[CV 1/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.660 total time=   8.5s\n",
      "[CV 2/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.632 total time=   6.5s\n",
      "[CV 3/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.635 total time=   6.8s\n",
      "[CV 4/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.652 total time=   9.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.001, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.642 total time=   7.6s\n",
      "[CV 1/5] END activation=tanh, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.605 total time=   3.9s\n",
      "[CV 2/5] END activation=tanh, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.616 total time=   3.6s\n",
      "[CV 3/5] END activation=tanh, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.633 total time=   4.9s\n",
      "[CV 4/5] END activation=tanh, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.642 total time=   6.0s\n",
      "[CV 5/5] END activation=tanh, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(50,), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=sgd, validation_fraction=0.1;, score=0.615 total time=   2.8s\n",
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.01, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6742441780173147\n",
      "Standard Deviation of Test Score: 0.007965163364414139\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 500, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6606359876385759\n",
      "Standard Deviation of Test Score: 0.004158572579435439\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6442996251584102\n",
      "Standard Deviation of Test Score: 0.010583021692251055\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.01, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6424982791098455\n",
      "Standard Deviation of Test Score: 0.010001974813163759\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (100, 50), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.633406226741491\n",
      "Standard Deviation of Test Score: 0.0041058900104044265\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6330039016476485\n",
      "Standard Deviation of Test Score: 0.021553063756830845\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.6318096439912873\n",
      "Standard Deviation of Test Score: 0.004163086599763534\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.01, 'activation': 'logistic'}\n",
      "Mean Test Score: 0.6309906066260991\n",
      "Standard Deviation of Test Score: 0.0015896197474912176\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100, 50,), (100, 100, 50,)],\n",
    "    'max_iter': [10, 100, 200, 500],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1],\n",
    "    'n_iter_no_change': [5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=mlp_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1', verbose=3)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV 1/5] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.662 total time=  52.5s\n",
      "[CV 2/5] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.662 total time=  53.9s\n",
      "[CV 3/5] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.654 total time=  54.8s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.659 total time=  55.2s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.663 total time= 2.1min\n",
      "[CV 1/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.625 total time=  12.7s\n",
      "[CV 2/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.679 total time=  17.9s\n",
      "[CV 3/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.643 total time=   8.2s\n",
      "[CV 4/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.653 total time=   9.2s\n",
      "[CV 5/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=100, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.629 total time=   4.9s\n",
      "[CV 1/5] END activation=logistic, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.634 total time=  25.0s\n",
      "[CV 2/5] END activation=logistic, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.627 total time=  25.5s\n",
      "[CV 3/5] END activation=logistic, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.619 total time=  24.8s\n",
      "[CV 4/5] END activation=logistic, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.634 total time=  23.5s\n",
      "[CV 5/5] END activation=logistic, alpha=0.01, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.1, max_iter=100, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.625 total time=  25.2s\n",
      "[CV 1/5] END activation=relu, alpha=0.01, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.624 total time=   7.4s\n",
      "[CV 2/5] END activation=relu, alpha=0.01, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.642 total time=   8.4s\n",
      "[CV 3/5] END activation=relu, alpha=0.01, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.646 total time=  12.7s\n",
      "[CV 4/5] END activation=relu, alpha=0.01, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.665 total time=  13.1s\n",
      "[CV 5/5] END activation=relu, alpha=0.01, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.01, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.644 total time=  12.0s\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(15, 15), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.634 total time=  15.1s\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(15, 15), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.649 total time=  21.5s\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(15, 15), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.649 total time=  27.1s\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(15, 15), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.658 total time=  12.8s\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, batch_size=64, early_stopping=True, hidden_layer_sizes=(15, 15), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.632 total time=  12.7s\n",
      "[CV 1/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.630 total time=  49.4s\n",
      "[CV 2/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.633 total time=  49.9s\n",
      "[CV 3/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.630 total time=  50.8s\n",
      "[CV 4/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.635 total time=  49.4s\n",
      "[CV 5/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.634 total time=  49.5s\n",
      "[CV 1/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.629 total time=  43.7s\n",
      "[CV 2/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.603 total time=16.6min\n",
      "[CV 3/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.629 total time=   4.0s\n",
      "[CV 4/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.647 total time=39.0min\n",
      "[CV 5/5] END activation=relu, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20), learning_rate_init=0.01, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.633 total time=   7.1s\n",
      "[CV 1/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.552 total time=   2.3s\n",
      "[CV 2/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.640 total time=   1.4s\n",
      "[CV 3/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.000 total time=   1.4s\n",
      "[CV 4/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.654 total time=   1.4s\n",
      "[CV 5/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.554 total time=   1.7s\n",
      "[CV 1/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.627 total time=   1.2s\n",
      "[CV 2/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.667 total time=   0.9s\n",
      "[CV 3/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.640 total time=   1.8s\n",
      "[CV 4/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.652 total time=   2.5s\n",
      "[CV 5/5] END activation=relu, alpha=0.001, batch_size=512, early_stopping=True, hidden_layer_sizes=(20, 40, 20), learning_rate_init=0.1, max_iter=500, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.528 total time=   1.2s\n",
      "[CV 1/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.638 total time=   3.1s\n",
      "[CV 2/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.632 total time=   9.0s\n",
      "[CV 3/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.626 total time=   6.8s\n",
      "[CV 4/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.639 total time=   8.0s\n",
      "[CV 5/5] END activation=logistic, alpha=0.001, batch_size=64, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=200, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.636 total time=  11.8s\n",
      "[CV 1/5] END activation=logistic, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.633 total time=   2.2s\n",
      "[CV 2/5] END activation=logistic, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.634 total time=   2.1s\n",
      "[CV 3/5] END activation=logistic, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.632 total time=   2.2s\n",
      "[CV 4/5] END activation=logistic, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.626 total time=   2.3s\n",
      "[CV 5/5] END activation=logistic, alpha=0.0001, batch_size=128, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=adam, validation_fraction=0.1;, score=0.630 total time=   2.3s\n",
      "[CV 1/5] END activation=relu, alpha=0.0001, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.582 total time=   0.6s\n",
      "[CV 2/5] END activation=relu, alpha=0.0001, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.613 total time=   0.6s\n",
      "[CV 3/5] END activation=relu, alpha=0.0001, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.618 total time=   0.7s\n",
      "[CV 4/5] END activation=relu, alpha=0.0001, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.630 total time=   0.7s\n",
      "[CV 5/5] END activation=relu, alpha=0.0001, batch_size=1024, early_stopping=True, hidden_layer_sizes=(20, 20, 15), learning_rate_init=0.001, max_iter=10, n_iter_no_change=5, solver=lbfgs, validation_fraction=0.1;, score=0.621 total time=   0.7s\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [ (20, 20,), (15, 15), (20, 20, 15), (30, 15, 5), (20, 40, 20)],\n",
    "    'max_iter': [10, 100, 200, 500],\n",
    "    'activation': ['relu', 'logistic'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [64, 128, 512, 1024],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1],\n",
    "    'n_iter_no_change': [5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=mlp_classifier, param_distributions=param_dist, n_iter=20, cv=5, scoring='f1', verbose=3)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.61919403e-03, 1.82109284e+00, 1.10654855e+00, 3.03378105e-03,\n",
       "        6.78336620e-01, 1.89102073e+00, 3.79119730e+00, 1.65822263e+00,\n",
       "        1.79598830e+01, 3.01470757e-03]),\n",
       " 'std_fit_time': array([5.11930317e-04, 7.59441818e-01, 4.51067515e-01, 8.83858030e-05,\n",
       "        1.29925489e-02, 7.05474773e-02, 3.95697924e-02, 1.69730612e-01,\n",
       "        2.14975348e-01, 6.61634807e-04]),\n",
       " 'mean_score_time': array([0.        , 0.0076519 , 0.00797229, 0.        , 0.00977125,\n",
       "        0.00924149, 0.00781903, 0.01296096, 0.01214128, 0.        ]),\n",
       " 'std_score_time': array([0.        , 0.00049389, 0.00104848, 0.        , 0.00078557,\n",
       "        0.00066491, 0.00042658, 0.00129318, 0.00108396, 0.        ]),\n",
       " 'param_validation_fraction': masked_array(data=[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['adam', 'adam', 'sgd', 'sgd', 'lbfgs', 'sgd', 'lbfgs',\n",
       "                    'adam', 'lbfgs', 'adam'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_iter_no_change': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[100, 200, 200, 100, 10, 10, 200, 200, 200, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate_init': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.1, 0.1, 0.01, 0.1, 0.001,\n",
       "                    0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[(100, 100, 50), (50,), (50,), (100, 100, 50),\n",
       "                    (100, 50), (100, 50), (50,), (100, 100, 50),\n",
       "                    (100, 100, 50), (100, 100, 50)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_early_stopping': masked_array(data=[True, True, True, True, True, True, True, True, True,\n",
       "                    True],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_batch_size': masked_array(data=[32, 32, 64, 64, 128, 32, 128, 64, 32, 64],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.01, 0.01, 0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.01,\n",
       "                    0.001, 0.0001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_activation': masked_array(data=['sigmoid', 'tanh', 'relu', 'sigmoid', 'relu', 'tanh',\n",
       "                    'tanh', 'tanh', 'tanh', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'sigmoid'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'relu'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'sigmoid'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 128,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'relu'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'sgd',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.01,\n",
       "   'hidden_layer_sizes': (50,),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 128,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.1,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.01,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'lbfgs',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 200,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 32,\n",
       "   'alpha': 0.001,\n",
       "   'activation': 'tanh'},\n",
       "  {'validation_fraction': 0.1,\n",
       "   'solver': 'adam',\n",
       "   'n_iter_no_change': 5,\n",
       "   'max_iter': 10,\n",
       "   'learning_rate_init': 0.01,\n",
       "   'hidden_layer_sizes': (100, 100, 50),\n",
       "   'early_stopping': True,\n",
       "   'batch_size': 64,\n",
       "   'alpha': 0.0001,\n",
       "   'activation': 'sigmoid'}],\n",
       " 'split0_test_score': array([       nan, 0.31698565, 0.29187192,        nan, 0.3007335 ,\n",
       "        0.27812114, 0.37974684, 0.31156381, 0.39982031,        nan]),\n",
       " 'split1_test_score': array([       nan, 0.26379201, 0.27424336,        nan, 0.27244582,\n",
       "        0.26335878, 0.38645418, 0.17793103, 0.39839929,        nan]),\n",
       " 'split2_test_score': array([       nan, 0.27977316, 0.28325123,        nan, 0.3039807 ,\n",
       "        0.25016119, 0.3972468 , 0.32105869, 0.42985843,        nan]),\n",
       " 'split3_test_score': array([       nan, 0.25786164, 0.26567349,        nan, 0.26348808,\n",
       "        0.26108682, 0.35792779, 0.27870813, 0.38013544,        nan]),\n",
       " 'split4_test_score': array([       nan, 0.31490385, 0.29828851,        nan, 0.28748451,\n",
       "        0.24661072, 0.37525988, 0.22413793, 0.42020563,        nan]),\n",
       " 'mean_test_score': array([       nan, 0.28666326, 0.2826657 ,        nan, 0.28562652,\n",
       "        0.25986773, 0.3793271 , 0.26267992, 0.40568382,        nan]),\n",
       " 'std_test_score': array([       nan, 0.0249683 , 0.01173746,        nan, 0.01569962,\n",
       "        0.01110699, 0.013012  , 0.05426321, 0.01752404,        nan]),\n",
       " 'rank_test_score': array([8, 3, 5, 8, 4, 7, 2, 6, 1, 8])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.6449099312633325\n",
      "Test: Accuracy: 0.6312464907355418, f1: 0.2574901074053137\n"
     ]
    }
   ],
   "source": [
    "# Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (30, 20, 10), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.001, 'activation': 'relu'}\n",
    "\n",
    "chosen_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(30, 20, 10),\n",
    "    activation='relu',\n",
    "    solver='lbfgs',\n",
    "    alpha=0.001,\n",
    "    batch_size=128,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=200,\n",
    "    n_iter_no_change=5,\n",
    "    validation_fraction=0.1,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "chosen_mlp.fit(X_train, y_train)\n",
    "y_train_pred = chosen_mlp.predict(X_train)\n",
    "y_val_pred = chosen_mlp.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.6893813699928893\n",
      "Test: Accuracy: 0.6562324536777091, f1: 0.26676646706586826\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "    subsample = 0.8,\n",
    "    n_estimators = 200,\n",
    "    min_samples_split = 5,\n",
    "    min_samples_leaf = 2,\n",
    "    min_impurity_decrease = 0.0,\n",
    "    max_features = None,\n",
    "    max_depth = 5,\n",
    "    loss = 'exponential',\n",
    "    learning_rate = 0.1,\n",
    "    criterion = 'friedman_mse'\n",
    ")\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "y_train_pred = gbc.predict(X_train)\n",
    "y_val_pred = gbc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.612062495062021\n",
      "Test: Accuracy: 0.6559517125210556, f1: 0.2570475901788421\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_val_pred = gnb.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.7000079007663743\n",
      "Test: Accuracy: 0.6645845030881528, f1: 0.26193050193050194\n"
     ]
    }
   ],
   "source": [
    "sc = StackingClassifier(estimators=[\n",
    "    ('mlp', chosen_mlp),\n",
    "    ('gbc', gbc),\n",
    "    ('gnb', gnb)\n",
    "])\n",
    "\n",
    "sc.fit(X_train, y_train)\n",
    "y_train_pred = sc.predict(X_train)\n",
    "y_val_pred = sc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbc.fit(X, y)\n",
    "test_pred = sc.predict(test)\n",
    "\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted_binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499502</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447319</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181183</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359339</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              readmitted_binary\n",
       "encounter_id                   \n",
       "499502                        0\n",
       "447319                        0\n",
       "309126                        0\n",
       "181183                        0\n",
       "359339                        0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame(test_pred, columns=['readmitted_binary'], index=test.index)\n",
    "\n",
    "to_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30530\n",
       "unique        2\n",
       "top          No\n",
       "freq      20012\n",
       "Name: readmitted_binary, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = to_submit['readmitted_binary'].map({1: 'Yes', 0: 'No'})\n",
    "to_submit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.to_csv(\"../data/output/submission_sk_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['length_of_stay_in_hospital_win_log', 'number_of_medications_log',\n",
       "       'number_of_medications', 'inpatient_visits_in_previous_year',\n",
       "       'number_lab_tests', 'inpatient_visits_in_previous_year_win_log',\n",
       "       'inpatient_visits_in_previous_year_log', 'number_diagnoses',\n",
       "       'length_of_stay_in_hospital_log', 'secondary_diagnosis_cat',\n",
       "       'med_metformin', 'payer_code', 'discharge_disposition',\n",
       "       'change_in_meds_during_hospitalization', 'discharge_disposition_cat_1',\n",
       "       'discharge_disposition_cat_3', 'gender', 'is_pulse_normal',\n",
       "       'admission_type_2', 'admission_source', 'a1c_test_result_2', 'age_2',\n",
       "       'a1c_test_result_0', 'glucose_test_result_1', 'age_0', 'age_8',\n",
       "       'primary_diagnosis_cat', 'discharge_disposition_cat_0',\n",
       "       'is_outpatient_visited', 'admission_type_4', 'is_inpatient_visited',\n",
       "       'is_emergency_visited', 'med_insulin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-23-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
