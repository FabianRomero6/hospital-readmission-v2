{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression, LassoCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel, SequentialFeatureSelector, RFE, SelectKBest, mutual_info_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.stats import boxcox, chi2_contingency\n",
    "from scipy.stats.mstats import winsorize\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "sns.set()\n",
    "sns.set_palette('cividis')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(\"..\", \"data\", \"clean\", \"x_train_encoded.csv\")\n",
    "val_path = os.path.join(\"..\", \"data\", \"clean\", \"x_val_encoded.csv\")\n",
    "test_path = os.path.join(\"..\", \"data\", \"clean\", \"test_clean.csv\")\n",
    "y_train_path = os.path.join(\"..\", \"data\", \"clean\", \"y_train_copy.csv\")\n",
    "y_val_path = os.path.join(\"..\", \"data\", \"clean\", \"y_val_copy_10.csv\")\n",
    "\n",
    "X_train = pd.read_csv(train_path, index_col=0)\n",
    "X_val = pd.read_csv(val_path, index_col=0)\n",
    "test = pd.read_csv(test_path, index_col=0)\n",
    "y_train = pd.read_csv(y_train_path, index_col=0)\n",
    "y_val = pd.read_csv(y_val_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape[0] + X_val.shape[0] == y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test.isna().sum() > 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[X_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[:, test.columns != X_train.columns].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[:, test.columns != X_train.columns].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emergency_visits_in_previous_year</th>\n",
       "      <th>inpatient_visits_in_previous_year</th>\n",
       "      <th>average_pulse_bpm</th>\n",
       "      <th>length_of_stay_in_hospital</th>\n",
       "      <th>number_lab_tests</th>\n",
       "      <th>non_lab_procedures</th>\n",
       "      <th>number_of_medications</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>admission_source_ Transfer from Ambulatory Surgery Center</th>\n",
       "      <th>admission_source_ Transfer from a Skilled Nursing Facility (SNF)</th>\n",
       "      <th>admission_source_ Transfer from another health care facility</th>\n",
       "      <th>admission_source_ Transfer from critial access hospital</th>\n",
       "      <th>admission_source_ Transfer from hospital inpt/same fac reslt in a sep claim</th>\n",
       "      <th>admission_source_Clinic Referral</th>\n",
       "      <th>admission_source_HMO Referral</th>\n",
       "      <th>admission_source_Normal Delivery</th>\n",
       "      <th>admission_source_Transfer from a hospital</th>\n",
       "      <th>admission_source_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.376484</td>\n",
       "      <td>-0.742379</td>\n",
       "      <td>-1.416840</td>\n",
       "      <td>-0.893048</td>\n",
       "      <td>1.727976</td>\n",
       "      <td>-0.956069</td>\n",
       "      <td>0.303272</td>\n",
       "      <td>0.316693</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.018289</td>\n",
       "      <td>1.678655</td>\n",
       "      <td>-1.243196</td>\n",
       "      <td>-0.352243</td>\n",
       "      <td>-1.682598</td>\n",
       "      <td>-0.956069</td>\n",
       "      <td>-0.090359</td>\n",
       "      <td>0.722132</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.376484</td>\n",
       "      <td>-0.742379</td>\n",
       "      <td>1.491699</td>\n",
       "      <td>0.409978</td>\n",
       "      <td>0.952846</td>\n",
       "      <td>1.816751</td>\n",
       "      <td>1.257188</td>\n",
       "      <td>-0.650392</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.376484</td>\n",
       "      <td>-0.742379</td>\n",
       "      <td>0.927356</td>\n",
       "      <td>-0.893048</td>\n",
       "      <td>-0.184012</td>\n",
       "      <td>-0.956069</td>\n",
       "      <td>-0.572126</td>\n",
       "      <td>0.722132</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.376484</td>\n",
       "      <td>-0.742379</td>\n",
       "      <td>0.927356</td>\n",
       "      <td>-0.352243</td>\n",
       "      <td>0.901171</td>\n",
       "      <td>0.744078</td>\n",
       "      <td>-0.239315</td>\n",
       "      <td>-0.136549</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   emergency_visits_in_previous_year  inpatient_visits_in_previous_year  \\\n",
       "0                          -0.376484                          -0.742379   \n",
       "1                           3.018289                           1.678655   \n",
       "2                          -0.376484                          -0.742379   \n",
       "3                          -0.376484                          -0.742379   \n",
       "4                          -0.376484                          -0.742379   \n",
       "\n",
       "   average_pulse_bpm  length_of_stay_in_hospital  number_lab_tests  \\\n",
       "0          -1.416840                   -0.893048          1.727976   \n",
       "1          -1.243196                   -0.352243         -1.682598   \n",
       "2           1.491699                    0.409978          0.952846   \n",
       "3           0.927356                   -0.893048         -0.184012   \n",
       "4           0.927356                   -0.352243          0.901171   \n",
       "\n",
       "   non_lab_procedures  number_of_medications  number_diagnoses  gender  age  \\\n",
       "0           -0.956069               0.303272          0.316693       0    7   \n",
       "1           -0.956069              -0.090359          0.722132       0    9   \n",
       "2            1.816751               1.257188         -0.650392       0    5   \n",
       "3           -0.956069              -0.572126          0.722132       0    6   \n",
       "4            0.744078              -0.239315         -0.136549       1    7   \n",
       "\n",
       "   ...  admission_source_ Transfer from Ambulatory Surgery Center  \\\n",
       "0  ...                                              False           \n",
       "1  ...                                              False           \n",
       "2  ...                                              False           \n",
       "3  ...                                              False           \n",
       "4  ...                                              False           \n",
       "\n",
       "   admission_source_ Transfer from a Skilled Nursing Facility (SNF)  \\\n",
       "0                                              False                  \n",
       "1                                              False                  \n",
       "2                                              False                  \n",
       "3                                              False                  \n",
       "4                                              False                  \n",
       "\n",
       "   admission_source_ Transfer from another health care facility  \\\n",
       "0                                              False              \n",
       "1                                              False              \n",
       "2                                              False              \n",
       "3                                              False              \n",
       "4                                              False              \n",
       "\n",
       "   admission_source_ Transfer from critial access hospital  \\\n",
       "0                                              False         \n",
       "1                                              False         \n",
       "2                                              False         \n",
       "3                                              False         \n",
       "4                                              False         \n",
       "\n",
       "   admission_source_ Transfer from hospital inpt/same fac reslt in a sep claim  \\\n",
       "0                                              False                             \n",
       "1                                              False                             \n",
       "2                                              False                             \n",
       "3                                              False                             \n",
       "4                                              False                             \n",
       "\n",
       "   admission_source_Clinic Referral  admission_source_HMO Referral  \\\n",
       "0                             False                          False   \n",
       "1                             False                          False   \n",
       "2                             False                          False   \n",
       "3                             False                          False   \n",
       "4                             False                          False   \n",
       "\n",
       "   admission_source_Normal Delivery  \\\n",
       "0                             False   \n",
       "1                             False   \n",
       "2                             False   \n",
       "3                             False   \n",
       "4                             False   \n",
       "\n",
       "   admission_source_Transfer from a hospital  admission_source_Unknown  \n",
       "0                                      False                     False  \n",
       "1                                      False                      True  \n",
       "2                                      False                      True  \n",
       "3                                      False                     False  \n",
       "4                                      False                     False  \n",
       "\n",
       "[5 rows x 130 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y.loc[X_train.index]\n",
    "# y_val = y.loc[X_val.index]\n",
    "\n",
    "# for the imported y\n",
    "y = pd.concat([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115504, 130)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([X_train, X_val], axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 1.0, f1: 1.0\n",
      "Test: Accuracy: 0.839135317237507, f1: 0.2219959266802444\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_rfc = rfc.predict(X_train)\n",
    "y_pred_rfc = rfc.predict(X_val)\n",
    "\n",
    "print(f\"Train: Accuracy: {accuracy_score(y_train, y_train_pred_rfc)}, f1: {f1_score(y_train, y_train_pred_rfc)}\")\n",
    "print(f\"Test: Accuracy: {accuracy_score(y_val, y_pred_rfc)}, f1: {f1_score(y_val, y_pred_rfc)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    f1_s = []\n",
    "    \n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        X_train, X_val = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        y_train, y_val = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        value_train = accuracy_score(y_train, y_train_pred)\n",
    "        value_test = accuracy_score(y_val, y_val_pred)\n",
    "        value_f1 = f1_score(y_val, y_val_pred)\n",
    "        \n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        f1_s.append(value_f1)\n",
    "        \n",
    "    avg_train = round(np.mean(score_train), 3)\n",
    "    avg_test = round(np.mean(score_test), 3)\n",
    "    std_train = round(np.std(score_train), 2)\n",
    "    std_test = round(np.std(score_test), 2)\n",
    "    avg_f1 = round(np.mean(f1_s), 6)\n",
    "    std_f1 = round(np.std(f1_s), 6)\n",
    "\n",
    "    return str(avg_train) + '+/-' + str(std_train), \\\n",
    "        str(avg_test) + '+/-' + str(std_test), str(avg_f1) + '+/-' + str(std_f1)\n",
    "\n",
    "def show_results(df, *args):\n",
    "    for i, arg in enumerate(args):\n",
    "        print(f\"{i+1}th call of rfc: {arg}\")\n",
    "        avg_train, avg_test, f1 = evaluate(arg)\n",
    "        df.iloc[i] = avg_train, avg_test, f1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_depth=8, n_estimators=50, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_depth=8, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_depth=8, n_estimators=200, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_depth=8, n_estimators=300, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_depth=8, n_estimators=500, random_state=69)\n"
     ]
    }
   ],
   "source": [
    "## reviewing the number of estimators used\n",
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=value,\n",
    "            max_depth=8\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "n_est = [50, 100, 200, 300, 500]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=n_est)\n",
    "\n",
    "results_est = show_results(results_empty, *get_models(n_est))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.655+/-0.0</td>\n",
       "      <td>0.648+/-0.0</td>\n",
       "      <td>0.645488+/-0.008197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.656+/-0.0</td>\n",
       "      <td>0.649+/-0.0</td>\n",
       "      <td>0.647746+/-0.007273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.658+/-0.0</td>\n",
       "      <td>0.65+/-0.0</td>\n",
       "      <td>0.64778+/-0.002413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.658+/-0.0</td>\n",
       "      <td>0.65+/-0.0</td>\n",
       "      <td>0.650903+/-0.005649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.659+/-0.0</td>\n",
       "      <td>0.65+/-0.0</td>\n",
       "      <td>0.65064+/-0.003322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "50   0.655+/-0.0  0.648+/-0.0  0.645488+/-0.008197\n",
       "100  0.656+/-0.0  0.649+/-0.0  0.647746+/-0.007273\n",
       "200  0.658+/-0.0   0.65+/-0.0   0.64778+/-0.002413\n",
       "300  0.658+/-0.0   0.65+/-0.0  0.650903+/-0.005649\n",
       "500  0.659+/-0.0   0.65+/-0.0   0.65064+/-0.003322"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_depth=2, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_depth=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_depth=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_depth=12, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_depth=16, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.613+/-0.0</td>\n",
       "      <td>0.612+/-0.0</td>\n",
       "      <td>0.58351+/-0.011287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.624+/-0.0</td>\n",
       "      <td>0.623+/-0.0</td>\n",
       "      <td>0.618239+/-0.013842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.656+/-0.0</td>\n",
       "      <td>0.649+/-0.0</td>\n",
       "      <td>0.647173+/-0.005781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.728+/-0.0</td>\n",
       "      <td>0.705+/-0.0</td>\n",
       "      <td>0.705984+/-0.00273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.841+/-0.0</td>\n",
       "      <td>0.801+/-0.0</td>\n",
       "      <td>0.80331+/-0.002756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.996+/-0.0</td>\n",
       "      <td>0.996277+/-0.000683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train         Test                   f1\n",
       "2.0   0.613+/-0.0  0.612+/-0.0   0.58351+/-0.011287\n",
       "4.0   0.624+/-0.0  0.623+/-0.0  0.618239+/-0.013842\n",
       "8.0   0.656+/-0.0  0.649+/-0.0  0.647173+/-0.005781\n",
       "12.0  0.728+/-0.0  0.705+/-0.0   0.705984+/-0.00273\n",
       "16.0  0.841+/-0.0  0.801+/-0.0   0.80331+/-0.002756\n",
       "NaN     1.0+/-0.0  0.996+/-0.0  0.996277+/-0.000683"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            n_estimators=100,\n",
    "            max_depth=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "depths = [2, 4, 8, 12, 16, None]\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=depths)\n",
    "\n",
    "results_depth = show_results(results_empty, *get_models(depths))\n",
    "\n",
    "results_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.59+/-0.01</td>\n",
       "      <td>0.589+/-0.0</td>\n",
       "      <td>0.263862+/-0.028116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.617+/-0.0</td>\n",
       "      <td>0.615+/-0.0</td>\n",
       "      <td>0.407019+/-0.012767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.651+/-0.0</td>\n",
       "      <td>0.646+/-0.0</td>\n",
       "      <td>0.499245+/-0.003593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>0.722+/-0.0</td>\n",
       "      <td>0.702+/-0.0</td>\n",
       "      <td>0.609754+/-0.00611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.831+/-0.0</td>\n",
       "      <td>0.795+/-0.0</td>\n",
       "      <td>0.748823+/-0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.984+/-0.0</td>\n",
       "      <td>0.981708+/-0.000528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Train         Test                   f1\n",
       "2.0   0.59+/-0.01  0.589+/-0.0  0.263862+/-0.028116\n",
       "4.0   0.617+/-0.0  0.615+/-0.0  0.407019+/-0.012767\n",
       "8.0   0.651+/-0.0  0.646+/-0.0  0.499245+/-0.003593\n",
       "12.0  0.722+/-0.0  0.702+/-0.0   0.609754+/-0.00611\n",
       "16.0  0.831+/-0.0  0.795+/-0.0  0.748823+/-0.004432\n",
       "NaN     1.0+/-0.0  0.984+/-0.0  0.981708+/-0.000528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(min_samples_split=4, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(min_samples_split=8, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(min_samples_split=16, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(min_samples_split=32, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(min_samples_split=64, random_state=69)\n",
      "7th call of rfc: RandomForestClassifier(min_samples_split=128, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.205121+/-0.003511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.984+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.209059+/-0.011962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.923+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.206717+/-0.007306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.88+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.195921+/-0.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.856+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.176999+/-0.013797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.843+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.162672+/-0.009995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.833+/-0.0</td>\n",
       "      <td>0.138544+/-0.010453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "2      1.0+/-0.0  0.836+/-0.0  0.205121+/-0.003511\n",
       "4    0.984+/-0.0  0.835+/-0.0  0.209059+/-0.011962\n",
       "8    0.923+/-0.0  0.836+/-0.0  0.206717+/-0.007306\n",
       "16    0.88+/-0.0  0.836+/-0.0  0.195921+/-0.013186\n",
       "32   0.856+/-0.0  0.835+/-0.0  0.176999+/-0.013797\n",
       "64   0.843+/-0.0  0.835+/-0.0  0.162672+/-0.009995\n",
       "128  0.837+/-0.0  0.833+/-0.0  0.138544+/-0.010453"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            min_samples_split=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "splits = [2, 4, 8, 16, 32, 64, 128]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=splits)\n",
    "\n",
    "results_min_split = show_results(results_empty, *get_models(splits))\n",
    "results_min_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_samples=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_samples=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_samples=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_samples=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_samples=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.846+/-0.0</td>\n",
       "      <td>0.832+/-0.0</td>\n",
       "      <td>0.148549+/-0.008243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.864+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.169845+/-0.008981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.914+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.18544+/-0.005221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.974+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.200419+/-0.016275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.998+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.20819+/-0.011787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.212397+/-0.00629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train         Test                   f1\n",
       "0.1  0.846+/-0.0  0.832+/-0.0  0.148549+/-0.008243\n",
       "0.2  0.864+/-0.0  0.834+/-0.0  0.169845+/-0.008981\n",
       "0.4  0.914+/-0.0  0.835+/-0.0   0.18544+/-0.005221\n",
       "0.6  0.974+/-0.0  0.835+/-0.0  0.200419+/-0.016275\n",
       "0.8  0.998+/-0.0  0.836+/-0.0   0.20819+/-0.011787\n",
       "NaN    1.0+/-0.0  0.836+/-0.0   0.212397+/-0.00629"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_samples=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_samples = show_results(results_empty, *get_models(samples))\n",
    "results_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th call of rfc: RandomForestClassifier(max_features=0.1, random_state=69)\n",
      "2th call of rfc: RandomForestClassifier(max_features=0.2, random_state=69)\n",
      "3th call of rfc: RandomForestClassifier(max_features=0.4, random_state=69)\n",
      "4th call of rfc: RandomForestClassifier(max_features=0.6, random_state=69)\n",
      "5th call of rfc: RandomForestClassifier(max_features=0.8, random_state=69)\n",
      "6th call of rfc: RandomForestClassifier(max_features=None, random_state=69)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.834+/-0.0</td>\n",
       "      <td>0.172304+/-0.018237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.221058+/-0.007162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.837+/-0.0</td>\n",
       "      <td>0.257206+/-0.008665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.835+/-0.0</td>\n",
       "      <td>0.264981+/-0.009177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.281189+/-0.009322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>1.0+/-0.0</td>\n",
       "      <td>0.836+/-0.0</td>\n",
       "      <td>0.285535+/-0.010913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train         Test                   f1\n",
       "0.1  1.0+/-0.0  0.834+/-0.0  0.172304+/-0.018237\n",
       "0.2  1.0+/-0.0  0.836+/-0.0  0.221058+/-0.007162\n",
       "0.4  1.0+/-0.0  0.837+/-0.0  0.257206+/-0.008665\n",
       "0.6  1.0+/-0.0  0.835+/-0.0  0.264981+/-0.009177\n",
       "0.8  1.0+/-0.0  0.836+/-0.0  0.281189+/-0.009322\n",
       "NaN  1.0+/-0.0  0.836+/-0.0  0.285535+/-0.010913"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_models(values):\n",
    "    models = []\n",
    "    for value in values:\n",
    "        models.append(RandomForestClassifier(\n",
    "            random_state=69,\n",
    "            max_features=value\n",
    "        ))\n",
    "    return models\n",
    "\n",
    "samples = [0.1, 0.2, 0.4, 0.6, 0.8, None]\n",
    "\n",
    "results_empty = pd.DataFrame(columns=['Train', 'Test', 'f1'], index=samples)\n",
    "\n",
    "results_feat = show_results(results_empty, *get_models(samples))\n",
    "results_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': None, 'max_samples': None, 'min_samples_split': 4}\n",
      "Accuracy on Test Set: 0.8312745648512072\n",
      "f1 on Test Set: 0.2397216951296648\n"
     ]
    }
   ],
   "source": [
    "# performing a grid search with the best values\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [12, 16, None],\n",
    "    'min_samples_split': [4, 8, 16],\n",
    "    'max_samples': [0.6, 0.8, None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and the best estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_rf_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the performance on the test set\n",
    "y_pred = best_rf_classifier.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Accuracy on Test Set: {accuracy}\")\n",
    "print(f\"f1 on Test Set: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 1.0\n",
      "Test: Accuracy: 0.8884755755193712, f1: 0.03755299818291944\n"
     ]
    }
   ],
   "source": [
    "ch_rfc = RandomForestClassifier(random_state=69)\n",
    "ch_rfc.fit(X_train, y_train)\n",
    "y_train_pred = ch_rfc.predict(X_train)\n",
    "y_val_pred = ch_rfc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameter tuning\n",
    "\n",
    "will start directly with a random search, and then zoom in manually into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.0001, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 100, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.01, 'activation': 'sigmoid'}\n",
      "Mean Test Score: nan\n",
      "Standard Deviation of Test Score: nan\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.6946334080016434\n",
      "Standard Deviation of Test Score: 0.00477601760487908\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.01, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.6889165613256932\n",
      "Standard Deviation of Test Score: 0.010500692022997185\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.6872544323679999\n",
      "Standard Deviation of Test Score: 0.0021241637581313802\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (50,), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.63539985635116\n",
      "Standard Deviation of Test Score: 0.021732948501216834\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'max_iter': 10, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.6214210456030923\n",
      "Standard Deviation of Test Score: 0.04172856398572047\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    'hidden_layer_sizes': [(50,), (100, 50,), (100, 100, 50,)],\n",
    "    'max_iter': [10, 100, 200, 500],\n",
    "    'activation': ['relu', 'tanh', 'logistic'],\n",
    "    'solver': ['adam', 'sgd', 'lbfgs'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1],\n",
    "    'n_iter_no_change': [5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=mlp_classifier, param_distributions=param_dist, n_iter=10, cv=5, scoring='f1', verbose=1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'momentum': 0.5, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (256, 128, 64), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.9166217178852113\n",
      "Standard Deviation of Test Score: 0.023604917372087413\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'momentum': 0.9, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (128, 64), 'early_stopping': True, 'batch_size': 256, 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.8267892267393243\n",
      "Standard Deviation of Test Score: 0.10215802120102768\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'adam', 'n_iter_no_change': 5, 'momentum': 0.9, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.8209246471593697\n",
      "Standard Deviation of Test Score: 0.012043631049779334\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'momentum': 0.5, 'learning_rate_init': 0.1, 'hidden_layer_sizes': (128, 64), 'early_stopping': True, 'batch_size': 256, 'alpha': 0.001, 'activation': 'tanh'}\n",
      "Mean Test Score: 0.7938135798204303\n",
      "Standard Deviation of Test Score: 0.09480601927148176\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'momentum': 0.5, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (256, 128, 64), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.0001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.7438356310512256\n",
      "Standard Deviation of Test Score: 0.08917903086760952\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'sgd', 'n_iter_no_change': 5, 'momentum': 0.9, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (64, 32), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.7090826409583663\n",
      "Standard Deviation of Test Score: 0.018842066842264974\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'momentum': 0.5, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (128, 64), 'early_stopping': True, 'batch_size': 128, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6927579638846046\n",
      "Standard Deviation of Test Score: 0.0058761627709193655\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'momentum': 0.7, 'learning_rate_init': 0.0001, 'hidden_layer_sizes': (64, 32), 'early_stopping': True, 'batch_size': 64, 'alpha': 0.001, 'activation': 'relu'}\n",
      "Mean Test Score: 0.6744480042475499\n",
      "Standard Deviation of Test Score: 0.0037558755970575897\n"
     ]
    }
   ],
   "source": [
    "mlp_classifier = MLPClassifier()\n",
    "\n",
    "param_dist = {\n",
    "    \"learning_rate_init\": [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"momentum\": [0.5, 0.7, 0.9],\n",
    "    \"hidden_layer_sizes\": [(256, 128, 64), (128, 64), (64, 32)],\n",
    "    \"activation\": [\"relu\", \"logistic\", \"tanh\"],\n",
    "    \"solver\": ['adam', 'sgd', 'lbfgs'],\n",
    "    \"batch_size\": [64, 128, 256],\n",
    "    \"alpha\": [0.0001, 0.001, 0.01],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1],\n",
    "    'n_iter_no_change': [5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(mlp_classifier, param_dist, n_iter=10, cv=5, scoring='f1', verbose=1)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67078289\n",
      "Validation score: 0.619001\n",
      "Iteration 2, loss = 0.65882099\n",
      "Validation score: 0.624531\n",
      "Iteration 3, loss = 0.65220713\n",
      "Validation score: 0.633320\n",
      "Iteration 4, loss = 0.64667128\n",
      "Validation score: 0.636184\n",
      "Iteration 5, loss = 0.64157564\n",
      "Validation score: 0.639344\n",
      "Iteration 6, loss = 0.63612309\n",
      "Validation score: 0.635789\n",
      "Iteration 7, loss = 0.62993289\n",
      "Validation score: 0.647541\n",
      "Iteration 8, loss = 0.62459503\n",
      "Validation score: 0.641319\n",
      "Iteration 9, loss = 0.62077738\n",
      "Validation score: 0.644183\n",
      "Iteration 10, loss = 0.61489705\n",
      "Validation score: 0.656627\n",
      "Iteration 11, loss = 0.60944851\n",
      "Validation score: 0.660873\n",
      "Iteration 12, loss = 0.60422024\n",
      "Validation score: 0.668872\n",
      "Iteration 13, loss = 0.60028806\n",
      "Validation score: 0.666206\n",
      "Iteration 14, loss = 0.59491330\n",
      "Validation score: 0.670650\n",
      "Iteration 15, loss = 0.59134499\n",
      "Validation score: 0.674896\n",
      "Iteration 16, loss = 0.58640554\n",
      "Validation score: 0.673217\n",
      "Iteration 17, loss = 0.58162256\n",
      "Validation score: 0.671242\n",
      "Iteration 18, loss = 0.57774201\n",
      "Validation score: 0.681710\n",
      "Iteration 19, loss = 0.57308377\n",
      "Validation score: 0.672526\n",
      "Iteration 20, loss = 0.56858807\n",
      "Validation score: 0.686451\n",
      "Iteration 21, loss = 0.56512562\n",
      "Validation score: 0.685068\n",
      "Iteration 22, loss = 0.56127789\n",
      "Validation score: 0.700672\n",
      "Iteration 23, loss = 0.55614613\n",
      "Validation score: 0.696820\n",
      "Iteration 24, loss = 0.55446829\n",
      "Validation score: 0.702252\n",
      "Iteration 25, loss = 0.54899245\n",
      "Validation score: 0.709658\n",
      "Iteration 26, loss = 0.54649211\n",
      "Validation score: 0.706696\n",
      "Iteration 27, loss = 0.54269173\n",
      "Validation score: 0.717658\n",
      "Iteration 28, loss = 0.54027081\n",
      "Validation score: 0.716275\n",
      "Iteration 29, loss = 0.53643489\n",
      "Validation score: 0.712720\n",
      "Iteration 30, loss = 0.53377583\n",
      "Validation score: 0.714004\n",
      "Iteration 31, loss = 0.53034512\n",
      "Validation score: 0.719830\n",
      "Iteration 32, loss = 0.52615511\n",
      "Validation score: 0.716472\n",
      "Iteration 33, loss = 0.52322337\n",
      "Validation score: 0.730595\n",
      "Iteration 34, loss = 0.52047753\n",
      "Validation score: 0.740766\n",
      "Iteration 35, loss = 0.51704252\n",
      "Validation score: 0.720521\n",
      "Iteration 36, loss = 0.51472807\n",
      "Validation score: 0.741260\n",
      "Iteration 37, loss = 0.51082285\n",
      "Validation score: 0.741951\n",
      "Iteration 38, loss = 0.50764334\n",
      "Validation score: 0.733853\n",
      "Iteration 39, loss = 0.50622534\n",
      "Validation score: 0.743828\n",
      "Iteration 40, loss = 0.50470517\n",
      "Validation score: 0.754197\n",
      "Iteration 41, loss = 0.50126327\n",
      "Validation score: 0.756666\n",
      "Iteration 42, loss = 0.49733980\n",
      "Validation score: 0.767727\n",
      "Iteration 43, loss = 0.49538952\n",
      "Validation score: 0.748173\n",
      "Iteration 44, loss = 0.49507835\n",
      "Validation score: 0.747087\n",
      "Iteration 45, loss = 0.49229297\n",
      "Validation score: 0.744025\n",
      "Iteration 46, loss = 0.49027473\n",
      "Validation score: 0.744124\n",
      "Iteration 47, loss = 0.48685538\n",
      "Validation score: 0.749358\n",
      "Iteration 48, loss = 0.48565970\n",
      "Validation score: 0.755876\n",
      "Validation score did not improve more than tol=0.000100 for 5 consecutive epochs. Stopping.\n",
      "Train: Accuracy: 0.8013253535592952\n",
      "Test: Accuracy: 0.7052217855137564, f1: 0.2307692307692308\n"
     ]
    }
   ],
   "source": [
    "# validation_fraction': 0.1, 'solver': 'lbfgs', 'n_iter_no_change': 5, 'max_iter': 200, 'learning_rate_init': 0.001, 'hidden_layer_sizes': (100, 100, 50), 'early_stopping': True, 'batch_size': 32, 'alpha': 0.001, 'activation': 'tanh'\n",
    "\n",
    "chosen_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(32, 64, 128),\n",
    "    activation='relu',\n",
    "    solver='sgd',\n",
    "    alpha=0.01,\n",
    "    batch_size=64,\n",
    "    learning_rate_init=0.01,\n",
    "    momentum=0.9,\n",
    "    n_iter_no_change=5,\n",
    "    validation_fraction=0.1,\n",
    "    early_stopping=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "chosen_mlp.fit(X_train, y_train)\n",
    "y_train_pred = chosen_mlp.predict(X_train)\n",
    "y_val_pred = chosen_mlp.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.9920004740459825\n",
      "Test: Accuracy: 0.8291690061763054, f1: 0.17714672075726842\n"
     ]
    }
   ],
   "source": [
    "# paper suggested mlp\n",
    "\n",
    "chosen_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    momentum=0.9,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    ")\n",
    "\n",
    "chosen_mlp.fit(X_train, y_train)\n",
    "y_train_pred = chosen_mlp.predict(X_train)\n",
    "y_val_pred = chosen_mlp.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean_test_f1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Fabian\\Documents\\MSc\\1st Semester\\ML\\final-project\\hospital-readmission-v2\\notebooks\\prediction_clean.ipynb Cell 30\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fabian/Documents/MSc/1st%20Semester/ML/final-project/hospital-readmission-v2/notebooks/prediction_clean.ipynb#X42sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m random_search\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fabian/Documents/MSc/1st%20Semester/ML/final-project/hospital-readmission-v2/notebooks/prediction_clean.ipynb#X42sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m results \u001b[39m=\u001b[39m random_search\u001b[39m.\u001b[39mcv_results_\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Fabian/Documents/MSc/1st%20Semester/ML/final-project/hospital-readmission-v2/notebooks/prediction_clean.ipynb#X42sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m top_8_indices \u001b[39m=\u001b[39m results[\u001b[39m'\u001b[39m\u001b[39mmean_test_f1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39margsort()[\u001b[39m-\u001b[39m\u001b[39m8\u001b[39m:][::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fabian/Documents/MSc/1st%20Semester/ML/final-project/hospital-readmission-v2/notebooks/prediction_clean.ipynb#X42sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, idx \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(top_8_indices):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Fabian/Documents/MSc/1st%20Semester/ML/final-project/hospital-readmission-v2/notebooks/prediction_clean.ipynb#X42sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mTop \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Model:\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_test_f1'"
     ]
    }
   ],
   "source": [
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"loss\": [\"log_loss\", \"exponential\"],\n",
    "    \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"subsample\": [0.4, 0.8, 1.0],\n",
    "    \"learning_rate\": [0.1, 0.05, 0.01],\n",
    "    \"n_estimators\": [100, 200, 500, 1000],\n",
    "    \"max_depth\": [3, 5, 8],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"min_impurity_decrease\": [0.0, 0.01],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(gb_classifier, param_grid, n_iter=10, cv=5, scoring='f1', random_state=69, n_jobs=-1, verbose=2)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 1 Model:\n",
      "Parameters: {'subsample': 1.0, 'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_features': None, 'max_depth': 8, 'loss': 'log_loss', 'learning_rate': 0.1, 'criterion': 'squared_error'}\n",
      "Mean Test Score: 0.9270886914843464\n",
      "Standard Deviation of Test Score: 0.0032211162615861286\n",
      "\n",
      "Top 2 Model:\n",
      "Parameters: {'subsample': 0.8, 'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_features': 'sqrt', 'max_depth': 5, 'loss': 'exponential', 'learning_rate': 0.05, 'criterion': 'squared_error'}\n",
      "Mean Test Score: 0.7216418164139244\n",
      "Standard Deviation of Test Score: 0.0009307495164233584\n",
      "\n",
      "Top 3 Model:\n",
      "Parameters: {'subsample': 0.4, 'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 'sqrt', 'max_depth': 8, 'loss': 'log_loss', 'learning_rate': 0.01, 'criterion': 'friedman_mse'}\n",
      "Mean Test Score: 0.7206978986619772\n",
      "Standard Deviation of Test Score: 0.0016984506183134098\n",
      "\n",
      "Top 4 Model:\n",
      "Parameters: {'subsample': 0.8, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_features': None, 'max_depth': 5, 'loss': 'exponential', 'learning_rate': 0.1, 'criterion': 'squared_error'}\n",
      "Mean Test Score: 0.6994612755057367\n",
      "Standard Deviation of Test Score: 0.0020057133171192862\n",
      "\n",
      "Top 5 Model:\n",
      "Parameters: {'subsample': 0.4, 'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.01, 'max_features': 'sqrt', 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.05, 'criterion': 'friedman_mse'}\n",
      "Mean Test Score: 0.6494038095883724\n",
      "Standard Deviation of Test Score: 0.001719609427363715\n",
      "\n",
      "Top 6 Model:\n",
      "Parameters: {'subsample': 0.4, 'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0, 'max_features': 'sqrt', 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.05, 'criterion': 'squared_error'}\n",
      "Mean Test Score: 0.6489904170963857\n",
      "Standard Deviation of Test Score: 0.0018047732353823015\n",
      "\n",
      "Top 7 Model:\n",
      "Parameters: {'subsample': 0.4, 'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0, 'max_features': None, 'max_depth': 3, 'loss': 'log_loss', 'learning_rate': 0.05, 'criterion': 'friedman_mse'}\n",
      "Mean Test Score: 0.6485978093698666\n",
      "Standard Deviation of Test Score: 0.0006931959059649415\n",
      "\n",
      "Top 8 Model:\n",
      "Parameters: {'subsample': 1.0, 'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0, 'max_features': 'sqrt', 'max_depth': 3, 'loss': 'exponential', 'learning_rate': 0.01, 'criterion': 'friedman_mse'}\n",
      "Mean Test Score: 0.6143714241503806\n",
      "Standard Deviation of Test Score: 0.005768137814524612\n"
     ]
    }
   ],
   "source": [
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9919           0.0081           54.43s\n",
      "         2           0.9850           0.0066           53.29s\n",
      "         3           0.9788           0.0053           53.13s\n",
      "         4           0.9742           0.0060           52.83s\n",
      "         5           0.9698           0.0034           52.65s\n",
      "         6           0.9664           0.0049           52.84s\n",
      "         7           0.9633           0.0040           53.53s\n",
      "         8           0.9602           0.0021           53.98s\n",
      "         9           0.9577           0.0025           53.49s\n",
      "        10           0.9553           0.0017           53.57s\n",
      "        20           0.9414           0.0020           51.66s\n",
      "        30           0.9336           0.0076           46.79s\n",
      "        40           0.9269          -0.0007           42.97s\n",
      "        50           0.9223           0.0015           39.62s\n",
      "        60           0.9156          -0.0046           36.58s\n",
      "        70           0.9112          -0.0034           33.80s\n",
      "        80           0.9059          -0.0011           30.98s\n",
      "        90           0.9016           0.0023           28.28s\n",
      "       100           0.8968           0.0001           25.68s\n",
      "       200           0.8550          -0.0030            0.00s\n",
      "Train: Accuracy: 0.7147329540965474\n",
      "Test: Accuracy: 0.6922375070185289, f1: 0.277951589000494\n"
     ]
    }
   ],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "    subsample = 0.8,\n",
    "    n_estimators = 200,\n",
    "    min_samples_split = 5,\n",
    "    min_samples_leaf = 2,\n",
    "    min_impurity_decrease = 0.0,\n",
    "    max_features = None,\n",
    "    max_depth = 5,\n",
    "    loss = 'exponential',\n",
    "    learning_rate = 0.1,\n",
    "    criterion = 'friedman_mse',\n",
    "    random_state=69,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "y_train_pred = gbc.predict(X_train)\n",
    "y_val_pred = gbc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], \n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'gamma': [0.01, 0.1, 'auto', 'scale']} \n",
    "\n",
    "random_search = RandomizedSearchCV(svc, param_grid, n_iter=10, cv=5, scoring='f1', n_jobs=-1, verbose=3)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "results = random_search.cv_results_\n",
    "\n",
    "top_8_indices = results['mean_test_score'].argsort()[-8:][::-1]\n",
    "\n",
    "for i, idx in enumerate(top_8_indices):\n",
    "    print(f\"\\nTop {i + 1} Model:\")\n",
    "    print(f\"Parameters: {results['params'][idx]}\")\n",
    "    print(f\"Mean Test Score: {results['mean_test_score'][idx]}\")\n",
    "    print(f\"Standard Deviation of Test Score: {results['std_test_score'][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Accuracy: 0.5161471912775539\n",
      "Test: Accuracy: 0.15054744525547445, f1: 0.20505747126436782\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_train_pred = gnb.predict(X_train)\n",
    "y_val_pred = gnb.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9919           0.0081           55.72s\n",
      "         2           0.9850           0.0066           55.22s\n",
      "         3           0.9788           0.0053           55.25s\n",
      "         4           0.9742           0.0060           54.88s\n",
      "         5           0.9698           0.0034           54.48s\n",
      "         6           0.9664           0.0049           54.36s\n",
      "         7           0.9633           0.0040           54.06s\n",
      "         8           0.9602           0.0021           53.94s\n",
      "         9           0.9577           0.0025           53.75s\n",
      "        10           0.9553           0.0017           53.49s\n",
      "        20           0.9414           0.0020           49.72s\n",
      "        30           0.9336           0.0076           46.17s\n",
      "        40           0.9269          -0.0007           42.50s\n",
      "        50           0.9223           0.0015           39.34s\n",
      "        60           0.9156          -0.0046           36.36s\n",
      "        70           0.9112          -0.0034           33.52s\n",
      "        80           0.9059          -0.0011           30.81s\n",
      "        90           0.9016           0.0023           28.14s\n",
      "       100           0.8968           0.0001           25.46s\n",
      "       200           0.8550          -0.0030            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9920           0.0081           42.60s\n",
      "         2           0.9850           0.0067           43.12s\n",
      "         3           0.9790           0.0052           42.65s\n",
      "         4           0.9742           0.0056           42.63s\n",
      "         5           0.9697           0.0040           42.27s\n",
      "         6           0.9659           0.0039           41.91s\n",
      "         7           0.9629           0.0042           41.46s\n",
      "         8           0.9600           0.0025           41.14s\n",
      "         9           0.9573           0.0009           40.79s\n",
      "        10           0.9552           0.0032           40.44s\n",
      "        20           0.9414           0.0021           37.75s\n",
      "        30           0.9318           0.0029           34.93s\n",
      "        40           0.9250           0.0017           32.25s\n",
      "        50           0.9196           0.0004           29.78s\n",
      "        60           0.9137           0.0026           27.74s\n",
      "        70           0.9074           0.0051           25.68s\n",
      "        80           0.9020          -0.0013           23.65s\n",
      "        90           0.8981          -0.0019           21.64s\n",
      "       100           0.8937          -0.0013           19.58s\n",
      "       200           0.8497          -0.0015            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9917           0.0079           47.63s\n",
      "         2           0.9847           0.0068           46.60s\n",
      "         3           0.9786           0.0054           46.50s\n",
      "         4           0.9739           0.0065           45.96s\n",
      "         5           0.9694           0.0034           45.18s\n",
      "         6           0.9660           0.0054           44.77s\n",
      "         7           0.9623           0.0012           44.16s\n",
      "         8           0.9591           0.0014           45.30s\n",
      "         9           0.9571           0.0044           46.88s\n",
      "        10           0.9556           0.0044           47.70s\n",
      "        20           0.9410           0.0030           42.55s\n",
      "        30           0.9319          -0.0046           38.27s\n",
      "        40           0.9261          -0.0029           34.82s\n",
      "        50           0.9204          -0.0021           32.04s\n",
      "        60           0.9150           0.0025           29.53s\n",
      "        70           0.9090           0.0002           27.44s\n",
      "        80           0.9040          -0.0025           25.13s\n",
      "        90           0.9009           0.0002           22.72s\n",
      "       100           0.8959          -0.0023           20.51s\n",
      "       200           0.8522           0.0044            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9918           0.0078           42.98s\n",
      "         2           0.9850           0.0070           42.63s\n",
      "         3           0.9789           0.0051           41.97s\n",
      "         4           0.9743           0.0067           41.80s\n",
      "         5           0.9700           0.0039           41.90s\n",
      "         6           0.9659           0.0024           41.65s\n",
      "         7           0.9630           0.0039           41.25s\n",
      "         8           0.9597           0.0010           41.05s\n",
      "         9           0.9578           0.0044           40.73s\n",
      "        10           0.9563           0.0048           40.29s\n",
      "        20           0.9423           0.0034           37.88s\n",
      "        30           0.9329          -0.0003           35.13s\n",
      "        40           0.9259          -0.0044           32.58s\n",
      "        50           0.9210          -0.0022           30.18s\n",
      "        60           0.9163           0.0048           27.90s\n",
      "        70           0.9092          -0.0006           25.73s\n",
      "        80           0.9041           0.0003           23.89s\n",
      "        90           0.8987          -0.0018           21.81s\n",
      "       100           0.8942           0.0011           19.80s\n",
      "       200           0.8524           0.0021            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9919           0.0080           43.39s\n",
      "         2           0.9849           0.0066           42.47s\n",
      "         3           0.9792           0.0062           42.25s\n",
      "         4           0.9743           0.0052           42.41s\n",
      "         5           0.9698           0.0031           42.02s\n",
      "         6           0.9661           0.0039           41.64s\n",
      "         7           0.9632           0.0037           41.45s\n",
      "         8           0.9600           0.0018           41.90s\n",
      "         9           0.9578           0.0030           41.71s\n",
      "        10           0.9556           0.0027           41.28s\n",
      "        20           0.9411           0.0025           38.18s\n",
      "        30           0.9335           0.0049           35.11s\n",
      "        40           0.9266           0.0017           32.51s\n",
      "        50           0.9197          -0.0037           30.39s\n",
      "        60           0.9140          -0.0029           28.19s\n",
      "        70           0.9084          -0.0019           26.27s\n",
      "        80           0.9026          -0.0058           24.15s\n",
      "        90           0.8997          -0.0000           22.08s\n",
      "       100           0.8949          -0.0005           20.06s\n",
      "       200           0.8511          -0.0012            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1           0.9919           0.0080           41.95s\n",
      "         2           0.9850           0.0065           41.55s\n",
      "         3           0.9793           0.0064           41.07s\n",
      "         4           0.9744           0.0048           40.74s\n",
      "         5           0.9699           0.0034           40.54s\n",
      "         6           0.9659           0.0031           40.27s\n",
      "         7           0.9631           0.0053           40.39s\n",
      "         8           0.9598           0.0017           40.36s\n",
      "         9           0.9575           0.0039           40.15s\n",
      "        10           0.9553           0.0026           40.25s\n",
      "        20           0.9402          -0.0007           37.67s\n",
      "        30           0.9330           0.0037           34.53s\n",
      "        40           0.9262           0.0011           31.85s\n",
      "        50           0.9197          -0.0067           29.44s\n",
      "        60           0.9160           0.0002           27.22s\n",
      "        70           0.9098          -0.0008           25.09s\n",
      "        80           0.9038          -0.0058           23.07s\n",
      "        90           0.9004           0.0001           21.07s\n",
      "       100           0.8955           0.0003           19.09s\n",
      "       200           0.8505          -0.0004            0.00s\n",
      "Train: Accuracy: 0.71362684680414\n",
      "Test: Accuracy: 0.6912549129702414, f1: 0.27991487968570955\n"
     ]
    }
   ],
   "source": [
    "sc = StackingClassifier(estimators=[\n",
    "    ('mlp', chosen_mlp),\n",
    "    ('gbc', gbc),\n",
    "    ('gnb', gnb)\n",
    "])\n",
    "\n",
    "sc.fit(X_train, y_train)\n",
    "y_train_pred = sc.predict(X_train)\n",
    "y_val_pred = sc.predict(X_val)\n",
    "\n",
    "value_train = accuracy_score(y_train, y_train_pred)\n",
    "value_test = accuracy_score(y_val, y_val_pred)\n",
    "value_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Train: Accuracy: {value_train}\")\n",
    "print(f\"Test: Accuracy: {value_test}, f1: {value_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gbc.fit(X, y)\n",
    "test_pred = sc.predict(test)\n",
    "\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "og_test_path = os.path.join(\"..\", \"data\", \"input\", \"test.csv\")\n",
    "og_test = pd.read_csv(og_test_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted_binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499502</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447319</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309126</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181183</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359339</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              readmitted_binary\n",
       "encounter_id                   \n",
       "499502                        0\n",
       "447319                        0\n",
       "309126                        0\n",
       "181183                        0\n",
       "359339                        0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = pd.DataFrame(test_pred, columns=['readmitted_binary'], index=og_test.index)\n",
    "\n",
    "to_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30530\n",
       "unique        2\n",
       "top          No\n",
       "freq      20938\n",
       "Name: readmitted_binary, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_submit = to_submit['readmitted_binary'].map({1: 'Yes', 0: 'No'})\n",
    "to_submit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit.to_csv(\"../data/output/submission_sc_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_mean', 'non_lab_procedures.1',\n",
       "       'inpatient_visits_in_previous_year.1', 'average_pulse_bpm',\n",
       "       'emergency_visits_in_previous_year.1', 'number_diagnoses',\n",
       "       'number_of_medications_log', 'length_of_stay_in_hospital_log',\n",
       "       'number_lab_tests.1', 'race_0', 'race_3', 'gender', 'age_0', 'age_2',\n",
       "       'age_4', 'age_5', 'age_6', 'age_8', 'admission_type_4',\n",
       "       'discharge_disposition', 'a1c_test_result_2',\n",
       "       'change_in_meds_during_hospitalization', 'is_outpatient_visited',\n",
       "       'is_emergency_visited', 'is_inpatient_visited',\n",
       "       'discharge_disposition_cat_0', 'admission_source_cat_0',\n",
       "       'admission_source_cat_1', 'admission_source_cat_3', 'med_glimepiride',\n",
       "       'med_insulin', 'med_repaglinide', 'med_metformin'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group-23-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
